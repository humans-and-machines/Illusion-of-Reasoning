<!doctype html>
<html class="no-js" lang="en" data-content_root="../../../">
  <head><meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="../../../genindex.html"><link rel="search" title="Search" href="../../../search.html">

    <!-- Generated with Sphinx 8.2.3 and Furo 2025.09.25 -->
        <title>transformers.utils.import_utils - Illusion-of-Reasoning documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=d111a655" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo.css?v=580074bf" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo-extensions.css?v=8dab3a3b" />
    
    


<style>
  body {
    --color-code-background: #f2f2f2;
  --color-code-foreground: #1e1e1e;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle site navigation sidebar">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc" aria-label="Toggle table of contents sidebar">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <span class="icon"><svg><use href="#svg-menu"></use></svg></span>
      </label>
    </div>
    <div class="header-center">
      <a href="../../../index.html"><div class="brand">Illusion-of-Reasoning  documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../../index.html">
  
  <span class="sidebar-brand-text">Illusion-of-Reasoning  documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api/modules.html">src</a><input aria-label="Toggle navigation of src" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../api/src.html">src package</a><input aria-label="Toggle navigation of src package" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../api/src.analysis.html">src.analysis package</a><input aria-label="Toggle navigation of src.analysis package" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/src.analysis.common.html">src.analysis.common package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/src.analysis.core.html">src.analysis.core package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/src.analysis.figures.html">src.analysis.figures package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/src.analysis.h3_uncertainty.html">src.analysis.h3_uncertainty package</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../api/src.annotate.html">src.annotate package</a><input aria-label="Toggle navigation of src.annotate package" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4 has-children"><a class="reference internal" href="../../../api/src.annotate.backcompat.html">src.annotate.backcompat package</a><input aria-label="Toggle navigation of src.annotate.backcompat package" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../api/src.annotate.backcompat.tasks.html">src.annotate.backcompat.tasks package</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/src.annotate.cli.html">src.annotate.cli package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/src.annotate.core.html">src.annotate.core package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/src.annotate.infra.html">src.annotate.infra package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/src.annotate.tasks.html">src.annotate.tasks package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/src.common.html">src.common package</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../api/src.inference.html">src.inference package</a><input aria-label="Toggle navigation of src.inference package" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/src.inference.backends.html">src.inference.backends package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/src.inference.cli.html">src.inference.cli package</a></li>
<li class="toctree-l4 has-children"><a class="reference internal" href="../../../api/src.inference.domains.html">src.inference.domains package</a><input aria-label="Toggle navigation of src.inference.domains package" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../api/src.inference.domains.carpark.html">src.inference.domains.carpark package</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/src.inference.domains.crossword.html">src.inference.domains.crossword package</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/src.inference.domains.math.html">src.inference.domains.math package</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/src.inference.domains.summarize.html">src.inference.domains.summarize package</a></li>
</ul>
</li>
<li class="toctree-l4 has-children"><a class="reference internal" href="../../../api/src.inference.gateways.html">src.inference.gateways package</a><input aria-label="Toggle navigation of src.inference.gateways package" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../api/src.inference.gateways.providers.html">src.inference.gateways.providers package</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/src.inference.runners.html">src.inference.runners package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/src.inference.utils.html">src.inference.utils package</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../api/src.training.html">src.training package</a><input aria-label="Toggle navigation of src.training package" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/src.training.cli.html">src.training.cli package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/src.training.runtime.html">src.training.runtime package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/src.training.utils.html">src.training.utils package</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <h1>Source code for transformers.utils.import_utils</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2022 The HuggingFace Team. All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Import utilities: Utilities related to imports and our lazy inits.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">importlib.machinery</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">importlib.metadata</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">importlib.util</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">operator</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">shutil</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">subprocess</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">enum</span><span class="w"> </span><span class="kn">import</span> <span class="n">Enum</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">lru_cache</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">itertools</span><span class="w"> </span><span class="kn">import</span> <span class="n">chain</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">types</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModuleType</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">FrozenSet</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Set</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">packaging</span><span class="w"> </span><span class="kn">import</span> <span class="n">version</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">.</span><span class="w"> </span><span class="kn">import</span> <span class="n">logging</span>


<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">get_logger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>  <span class="c1"># pylint: disable=invalid-name</span>


<span class="c1"># TODO: This doesn&#39;t work for all packages (`bs4`, `faiss`, etc.) Talk to Sylvain to see how to do with it better.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_is_package_available</span><span class="p">(</span><span class="n">pkg_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">return_version</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="nb">bool</span><span class="p">]:</span>
    <span class="c1"># Check if the package spec exists and grab its version to avoid importing a local directory</span>
    <span class="n">package_exists</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="n">pkg_name</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="n">package_version</span> <span class="o">=</span> <span class="s2">&quot;N/A&quot;</span>
    <span class="k">if</span> <span class="n">package_exists</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># TODO: Once python 3.9 support is dropped, `importlib.metadata.packages_distributions()`</span>
            <span class="c1"># should be used here to map from package name to distribution names</span>
            <span class="c1"># e.g. PIL -&gt; Pillow, Pillow-SIMD; quark -&gt; amd-quark; onnxruntime -&gt; onnxruntime-gpu.</span>
            <span class="c1"># `importlib.metadata.packages_distributions()` is not available in Python 3.9.</span>

            <span class="c1"># Primary method to get the package version</span>
            <span class="n">package_version</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="n">pkg_name</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">PackageNotFoundError</span><span class="p">:</span>
            <span class="c1"># Fallback method: Only for &quot;torch&quot; and versions containing &quot;dev&quot;</span>
            <span class="k">if</span> <span class="n">pkg_name</span> <span class="o">==</span> <span class="s2">&quot;torch&quot;</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">package</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">import_module</span><span class="p">(</span><span class="n">pkg_name</span><span class="p">)</span>
                    <span class="n">temp_version</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">package</span><span class="p">,</span> <span class="s2">&quot;__version__&quot;</span><span class="p">,</span> <span class="s2">&quot;N/A&quot;</span><span class="p">)</span>
                    <span class="c1"># Check if the version contains &quot;dev&quot;</span>
                    <span class="k">if</span> <span class="s2">&quot;dev&quot;</span> <span class="ow">in</span> <span class="n">temp_version</span><span class="p">:</span>
                        <span class="n">package_version</span> <span class="o">=</span> <span class="n">temp_version</span>
                        <span class="n">package_exists</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">package_exists</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                    <span class="c1"># If the package can&#39;t be imported, it&#39;s not available</span>
                    <span class="n">package_exists</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">elif</span> <span class="n">pkg_name</span> <span class="o">==</span> <span class="s2">&quot;quark&quot;</span><span class="p">:</span>
                <span class="c1"># TODO: remove once `importlib.metadata.packages_distributions()` is supported.</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">package_version</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;amd-quark&quot;</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                    <span class="n">package_exists</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># For packages other than &quot;torch&quot;, don&#39;t attempt the fallback and set as not available</span>
                <span class="n">package_exists</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Detected </span><span class="si">{</span><span class="n">pkg_name</span><span class="si">}</span><span class="s2"> version: </span><span class="si">{</span><span class="n">package_version</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">return_version</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">package_exists</span><span class="p">,</span> <span class="n">package_version</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">package_exists</span>


<span class="n">ENV_VARS_TRUE_VALUES</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;ON&quot;</span><span class="p">,</span> <span class="s2">&quot;YES&quot;</span><span class="p">,</span> <span class="s2">&quot;TRUE&quot;</span><span class="p">}</span>
<span class="n">ENV_VARS_TRUE_AND_AUTO_VALUES</span> <span class="o">=</span> <span class="n">ENV_VARS_TRUE_VALUES</span><span class="o">.</span><span class="n">union</span><span class="p">({</span><span class="s2">&quot;AUTO&quot;</span><span class="p">})</span>

<span class="n">USE_TF</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;USE_TF&quot;</span><span class="p">,</span> <span class="s2">&quot;AUTO&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>
<span class="n">USE_TORCH</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;USE_TORCH&quot;</span><span class="p">,</span> <span class="s2">&quot;AUTO&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>
<span class="n">USE_JAX</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;USE_FLAX&quot;</span><span class="p">,</span> <span class="s2">&quot;AUTO&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>

<span class="c1"># Try to run a native pytorch job in an environment with TorchXLA installed by setting this value to 0.</span>
<span class="n">USE_TORCH_XLA</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;USE_TORCH_XLA&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>

<span class="n">FORCE_TF_AVAILABLE</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;FORCE_TF_AVAILABLE&quot;</span><span class="p">,</span> <span class="s2">&quot;AUTO&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>

<span class="c1"># `transformers` requires `torch&gt;=1.11` but this variable is exposed publicly, and we can&#39;t simply remove it.</span>
<span class="c1"># This is the version of torch required to run torch.fx features and torch.onnx with dictionary inputs.</span>
<span class="n">TORCH_FX_REQUIRED_VERSION</span> <span class="o">=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s2">&quot;1.10&quot;</span><span class="p">)</span>

<span class="n">ACCELERATE_MIN_VERSION</span> <span class="o">=</span> <span class="s2">&quot;0.26.0&quot;</span>
<span class="n">SCHEDULEFREE_MIN_VERSION</span> <span class="o">=</span> <span class="s2">&quot;1.2.6&quot;</span>
<span class="n">FSDP_MIN_VERSION</span> <span class="o">=</span> <span class="s2">&quot;1.12.0&quot;</span>
<span class="n">GGUF_MIN_VERSION</span> <span class="o">=</span> <span class="s2">&quot;0.10.0&quot;</span>
<span class="n">XLA_FSDPV2_MIN_VERSION</span> <span class="o">=</span> <span class="s2">&quot;2.2.0&quot;</span>
<span class="n">HQQ_MIN_VERSION</span> <span class="o">=</span> <span class="s2">&quot;0.2.1&quot;</span>
<span class="n">VPTQ_MIN_VERSION</span> <span class="o">=</span> <span class="s2">&quot;0.0.4&quot;</span>
<span class="n">TORCHAO_MIN_VERSION</span> <span class="o">=</span> <span class="s2">&quot;0.4.0&quot;</span>
<span class="n">AUTOROUND_MIN_VERSION</span> <span class="o">=</span> <span class="s2">&quot;0.5.0&quot;</span>

<span class="n">_accelerate_available</span><span class="p">,</span> <span class="n">_accelerate_version</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;accelerate&quot;</span><span class="p">,</span> <span class="n">return_version</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">_apex_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;apex&quot;</span><span class="p">)</span>
<span class="n">_apollo_torch_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;apollo_torch&quot;</span><span class="p">)</span>
<span class="n">_aqlm_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;aqlm&quot;</span><span class="p">)</span>
<span class="n">_vptq_available</span><span class="p">,</span> <span class="n">_vptq_version</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;vptq&quot;</span><span class="p">,</span> <span class="n">return_version</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">_av_available</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;av&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="n">_decord_available</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;decord&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="n">_bitsandbytes_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;bitsandbytes&quot;</span><span class="p">)</span>
<span class="n">_eetq_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;eetq&quot;</span><span class="p">)</span>
<span class="n">_fbgemm_gpu_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;fbgemm_gpu&quot;</span><span class="p">)</span>
<span class="n">_galore_torch_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;galore_torch&quot;</span><span class="p">)</span>
<span class="n">_lomo_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;lomo_optim&quot;</span><span class="p">)</span>
<span class="n">_grokadamw_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;grokadamw&quot;</span><span class="p">)</span>
<span class="n">_schedulefree_available</span><span class="p">,</span> <span class="n">_schedulefree_version</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;schedulefree&quot;</span><span class="p">,</span> <span class="n">return_version</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># `importlib.metadata.version` doesn&#39;t work with `bs4` but `beautifulsoup4`. For `importlib.util.find_spec`, reversed.</span>
<span class="n">_bs4_available</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;bs4&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="n">_coloredlogs_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;coloredlogs&quot;</span><span class="p">)</span>
<span class="c1"># `importlib.metadata.util` doesn&#39;t work with `opencv-python-headless`.</span>
<span class="n">_cv2_available</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;cv2&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="n">_yt_dlp_available</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;yt_dlp&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="n">_datasets_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;datasets&quot;</span><span class="p">)</span>
<span class="n">_detectron2_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;detectron2&quot;</span><span class="p">)</span>
<span class="c1"># We need to check `faiss`, `faiss-cpu` and `faiss-gpu`.</span>
<span class="n">_faiss_available</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;faiss&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">_faiss_version</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;faiss&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Successfully imported faiss version </span><span class="si">{</span><span class="n">_faiss_version</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">except</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">PackageNotFoundError</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">_faiss_version</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;faiss-cpu&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Successfully imported faiss version </span><span class="si">{</span><span class="n">_faiss_version</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">PackageNotFoundError</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">_faiss_version</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;faiss-gpu&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Successfully imported faiss version </span><span class="si">{</span><span class="n">_faiss_version</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">PackageNotFoundError</span><span class="p">:</span>
            <span class="n">_faiss_available</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">_ftfy_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;ftfy&quot;</span><span class="p">)</span>
<span class="n">_g2p_en_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;g2p_en&quot;</span><span class="p">)</span>
<span class="n">_hadamard_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;fast_hadamard_transform&quot;</span><span class="p">)</span>
<span class="n">_ipex_available</span><span class="p">,</span> <span class="n">_ipex_version</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;intel_extension_for_pytorch&quot;</span><span class="p">,</span> <span class="n">return_version</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">_jieba_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;jieba&quot;</span><span class="p">)</span>
<span class="n">_jinja_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;jinja2&quot;</span><span class="p">)</span>
<span class="n">_kenlm_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;kenlm&quot;</span><span class="p">)</span>
<span class="n">_keras_nlp_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;keras_nlp&quot;</span><span class="p">)</span>
<span class="n">_levenshtein_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;Levenshtein&quot;</span><span class="p">)</span>
<span class="n">_librosa_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;librosa&quot;</span><span class="p">)</span>
<span class="n">_natten_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;natten&quot;</span><span class="p">)</span>
<span class="n">_nltk_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;nltk&quot;</span><span class="p">)</span>
<span class="n">_onnx_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;onnx&quot;</span><span class="p">)</span>
<span class="n">_openai_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;openai&quot;</span><span class="p">)</span>
<span class="n">_optimum_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;optimum&quot;</span><span class="p">)</span>
<span class="n">_auto_gptq_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;auto_gptq&quot;</span><span class="p">)</span>
<span class="n">_gptqmodel_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;gptqmodel&quot;</span><span class="p">)</span>
<span class="n">_auto_round_available</span><span class="p">,</span> <span class="n">_auto_round_version</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;auto_round&quot;</span><span class="p">,</span> <span class="n">return_version</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># `importlib.metadata.version` doesn&#39;t work with `awq`</span>
<span class="n">_auto_awq_available</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;awq&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="n">_quark_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;quark&quot;</span><span class="p">)</span>
<span class="n">_is_optimum_quanto_available</span> <span class="o">=</span> <span class="kc">False</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;optimum_quanto&quot;</span><span class="p">)</span>
    <span class="n">_is_optimum_quanto_available</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">except</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">PackageNotFoundError</span><span class="p">:</span>
    <span class="n">_is_optimum_quanto_available</span> <span class="o">=</span> <span class="kc">False</span>
<span class="c1"># For compressed_tensors, only check spec to allow compressed_tensors-nightly package</span>
<span class="n">_compressed_tensors_available</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;compressed_tensors&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="n">_pandas_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;pandas&quot;</span><span class="p">)</span>
<span class="n">_peft_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;peft&quot;</span><span class="p">)</span>
<span class="n">_phonemizer_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;phonemizer&quot;</span><span class="p">)</span>
<span class="n">_uroman_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;uroman&quot;</span><span class="p">)</span>
<span class="n">_psutil_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;psutil&quot;</span><span class="p">)</span>
<span class="n">_py3nvml_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;py3nvml&quot;</span><span class="p">)</span>
<span class="n">_pyctcdecode_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;pyctcdecode&quot;</span><span class="p">)</span>
<span class="n">_pygments_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;pygments&quot;</span><span class="p">)</span>
<span class="n">_pytesseract_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;pytesseract&quot;</span><span class="p">)</span>
<span class="n">_pytest_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;pytest&quot;</span><span class="p">)</span>
<span class="n">_pytorch_quantization_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;pytorch_quantization&quot;</span><span class="p">)</span>
<span class="n">_rjieba_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;rjieba&quot;</span><span class="p">)</span>
<span class="n">_sacremoses_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;sacremoses&quot;</span><span class="p">)</span>
<span class="n">_safetensors_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;safetensors&quot;</span><span class="p">)</span>
<span class="n">_scipy_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;scipy&quot;</span><span class="p">)</span>
<span class="n">_sentencepiece_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;sentencepiece&quot;</span><span class="p">)</span>
<span class="n">_is_seqio_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;seqio&quot;</span><span class="p">)</span>
<span class="n">_is_gguf_available</span><span class="p">,</span> <span class="n">_gguf_version</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;gguf&quot;</span><span class="p">,</span> <span class="n">return_version</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">_sklearn_available</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;sklearn&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="k">if</span> <span class="n">_sklearn_available</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;scikit-learn&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">PackageNotFoundError</span><span class="p">:</span>
        <span class="n">_sklearn_available</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">_smdistributed_available</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;smdistributed&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="n">_soundfile_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;soundfile&quot;</span><span class="p">)</span>
<span class="n">_spacy_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;spacy&quot;</span><span class="p">)</span>
<span class="n">_sudachipy_available</span><span class="p">,</span> <span class="n">_sudachipy_version</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;sudachipy&quot;</span><span class="p">,</span> <span class="n">return_version</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">_tensorflow_probability_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;tensorflow_probability&quot;</span><span class="p">)</span>
<span class="n">_tensorflow_text_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;tensorflow_text&quot;</span><span class="p">)</span>
<span class="n">_tf2onnx_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;tf2onnx&quot;</span><span class="p">)</span>
<span class="n">_timm_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;timm&quot;</span><span class="p">)</span>
<span class="n">_tokenizers_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;tokenizers&quot;</span><span class="p">)</span>
<span class="n">_torchaudio_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;torchaudio&quot;</span><span class="p">)</span>
<span class="n">_torchao_available</span><span class="p">,</span> <span class="n">_torchao_version</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;torchao&quot;</span><span class="p">,</span> <span class="n">return_version</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">_torchdistx_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;torchdistx&quot;</span><span class="p">)</span>
<span class="n">_torchvision_available</span><span class="p">,</span> <span class="n">_torchvision_version</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;torchvision&quot;</span><span class="p">,</span> <span class="n">return_version</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">_mlx_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;mlx&quot;</span><span class="p">)</span>
<span class="n">_num2words_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;num2words&quot;</span><span class="p">)</span>
<span class="n">_hqq_available</span><span class="p">,</span> <span class="n">_hqq_version</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;hqq&quot;</span><span class="p">,</span> <span class="n">return_version</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">_tiktoken_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;tiktoken&quot;</span><span class="p">)</span>
<span class="n">_blobfile_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;blobfile&quot;</span><span class="p">)</span>
<span class="n">_liger_kernel_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;liger_kernel&quot;</span><span class="p">)</span>
<span class="n">_triton_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;triton&quot;</span><span class="p">)</span>
<span class="n">_spqr_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;spqr_quant&quot;</span><span class="p">)</span>
<span class="n">_rich_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;rich&quot;</span><span class="p">)</span>
<span class="n">_kernels_available</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;kernels&quot;</span><span class="p">)</span>

<span class="n">_torch_version</span> <span class="o">=</span> <span class="s2">&quot;N/A&quot;</span>
<span class="n">_torch_available</span> <span class="o">=</span> <span class="kc">False</span>
<span class="k">if</span> <span class="n">USE_TORCH</span> <span class="ow">in</span> <span class="n">ENV_VARS_TRUE_AND_AUTO_VALUES</span> <span class="ow">and</span> <span class="n">USE_TF</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ENV_VARS_TRUE_VALUES</span><span class="p">:</span>
    <span class="n">_torch_available</span><span class="p">,</span> <span class="n">_torch_version</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">return_version</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">_torch_available</span><span class="p">:</span>
        <span class="n">_torch_available</span> <span class="o">=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">_torch_version</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s2">&quot;2.1.0&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_torch_available</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Disabling PyTorch because PyTorch &gt;= 2.1 is required but found </span><span class="si">{</span><span class="n">_torch_version</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Disabling PyTorch because USE_TF is set&quot;</span><span class="p">)</span>
    <span class="n">_torch_available</span> <span class="o">=</span> <span class="kc">False</span>


<span class="n">_tf_version</span> <span class="o">=</span> <span class="s2">&quot;N/A&quot;</span>
<span class="n">_tf_available</span> <span class="o">=</span> <span class="kc">False</span>
<span class="k">if</span> <span class="n">FORCE_TF_AVAILABLE</span> <span class="ow">in</span> <span class="n">ENV_VARS_TRUE_VALUES</span><span class="p">:</span>
    <span class="n">_tf_available</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">USE_TF</span> <span class="ow">in</span> <span class="n">ENV_VARS_TRUE_AND_AUTO_VALUES</span> <span class="ow">and</span> <span class="n">USE_TORCH</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ENV_VARS_TRUE_VALUES</span><span class="p">:</span>
        <span class="c1"># Note: _is_package_available(&quot;tensorflow&quot;) fails for tensorflow-cpu. Please test any changes to the line below</span>
        <span class="c1"># with tensorflow-cpu to make sure it still works!</span>
        <span class="n">_tf_available</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;tensorflow&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">_tf_available</span><span class="p">:</span>
            <span class="n">candidates</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s2">&quot;tensorflow&quot;</span><span class="p">,</span>
                <span class="s2">&quot;tensorflow-cpu&quot;</span><span class="p">,</span>
                <span class="s2">&quot;tensorflow-gpu&quot;</span><span class="p">,</span>
                <span class="s2">&quot;tf-nightly&quot;</span><span class="p">,</span>
                <span class="s2">&quot;tf-nightly-cpu&quot;</span><span class="p">,</span>
                <span class="s2">&quot;tf-nightly-gpu&quot;</span><span class="p">,</span>
                <span class="s2">&quot;tf-nightly-rocm&quot;</span><span class="p">,</span>
                <span class="s2">&quot;intel-tensorflow&quot;</span><span class="p">,</span>
                <span class="s2">&quot;intel-tensorflow-avx512&quot;</span><span class="p">,</span>
                <span class="s2">&quot;tensorflow-rocm&quot;</span><span class="p">,</span>
                <span class="s2">&quot;tensorflow-macos&quot;</span><span class="p">,</span>
                <span class="s2">&quot;tensorflow-aarch64&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">_tf_version</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="c1"># For the metadata, we have to look for both tensorflow and tensorflow-cpu</span>
            <span class="k">for</span> <span class="n">pkg</span> <span class="ow">in</span> <span class="n">candidates</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">_tf_version</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="n">pkg</span><span class="p">)</span>
                    <span class="k">break</span>
                <span class="k">except</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">PackageNotFoundError</span><span class="p">:</span>
                    <span class="k">pass</span>
            <span class="n">_tf_available</span> <span class="o">=</span> <span class="n">_tf_version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">_tf_available</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">_tf_version</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s2">&quot;2&quot;</span><span class="p">):</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;TensorFlow found but with version </span><span class="si">{</span><span class="n">_tf_version</span><span class="si">}</span><span class="s2">. Transformers requires version 2 minimum.&quot;</span>
                <span class="p">)</span>
                <span class="n">_tf_available</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Disabling Tensorflow because USE_TORCH is set&quot;</span><span class="p">)</span>


<span class="n">_essentia_available</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;essentia&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">_essentia_version</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;essentia&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Successfully imported essentia version </span><span class="si">{</span><span class="n">_essentia_version</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">except</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">PackageNotFoundError</span><span class="p">:</span>
    <span class="n">_essentia_version</span> <span class="o">=</span> <span class="kc">False</span>


<span class="n">_pretty_midi_available</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;pretty_midi&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">_pretty_midi_version</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;pretty_midi&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Successfully imported pretty_midi version </span><span class="si">{</span><span class="n">_pretty_midi_version</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">except</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">PackageNotFoundError</span><span class="p">:</span>
    <span class="n">_pretty_midi_available</span> <span class="o">=</span> <span class="kc">False</span>


<span class="n">ccl_version</span> <span class="o">=</span> <span class="s2">&quot;N/A&quot;</span>
<span class="n">_is_ccl_available</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;torch_ccl&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="ow">or</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;oneccl_bindings_for_pytorch&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">ccl_version</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;oneccl_bind_pt&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Detected oneccl_bind_pt version </span><span class="si">{</span><span class="n">ccl_version</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">except</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">PackageNotFoundError</span><span class="p">:</span>
    <span class="n">_is_ccl_available</span> <span class="o">=</span> <span class="kc">False</span>


<span class="n">_flax_available</span> <span class="o">=</span> <span class="kc">False</span>
<span class="k">if</span> <span class="n">USE_JAX</span> <span class="ow">in</span> <span class="n">ENV_VARS_TRUE_AND_AUTO_VALUES</span><span class="p">:</span>
    <span class="n">_flax_available</span><span class="p">,</span> <span class="n">_flax_version</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;flax&quot;</span><span class="p">,</span> <span class="n">return_version</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">_flax_available</span><span class="p">:</span>
        <span class="n">_jax_available</span><span class="p">,</span> <span class="n">_jax_version</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;jax&quot;</span><span class="p">,</span> <span class="n">return_version</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">_jax_available</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;JAX version </span><span class="si">{</span><span class="n">_jax_version</span><span class="si">}</span><span class="s2">, Flax version </span><span class="si">{</span><span class="n">_flax_version</span><span class="si">}</span><span class="s2"> available.&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_flax_available</span> <span class="o">=</span> <span class="n">_jax_available</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">_jax_version</span> <span class="o">=</span> <span class="n">_flax_version</span> <span class="o">=</span> <span class="s2">&quot;N/A&quot;</span>


<span class="n">_torch_xla_available</span> <span class="o">=</span> <span class="kc">False</span>
<span class="k">if</span> <span class="n">USE_TORCH_XLA</span> <span class="ow">in</span> <span class="n">ENV_VARS_TRUE_VALUES</span><span class="p">:</span>
    <span class="n">_torch_xla_available</span><span class="p">,</span> <span class="n">_torch_xla_version</span> <span class="o">=</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;torch_xla&quot;</span><span class="p">,</span> <span class="n">return_version</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">_torch_xla_available</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Torch XLA version </span><span class="si">{</span><span class="n">_torch_xla_version</span><span class="si">}</span><span class="s2"> available.&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_kenlm_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_kenlm_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_kernels_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_kernels_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_cv2_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_cv2_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_yt_dlp_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_yt_dlp_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_torch_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_accelerate_available</span><span class="p">(</span><span class="n">min_version</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">ACCELERATE_MIN_VERSION</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">_accelerate_available</span> <span class="ow">and</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">_accelerate_version</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">min_version</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_accelerator_available</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">is_torch_available</span><span class="p">():</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

        <span class="k">return</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;accelerator&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_deterministic</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check whether pytorch uses deterministic algorithms by looking if torch.set_deterministic_debug_mode() is set to 1 or 2&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">is_torch_available</span><span class="p">():</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">get_deterministic_debug_mode</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>

    <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_hadamard_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_hadamard_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_hqq_available</span><span class="p">(</span><span class="n">min_version</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">HQQ_MIN_VERSION</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">_hqq_available</span> <span class="ow">and</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">_hqq_version</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">min_version</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_pygments_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_pygments_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_torch_version</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_torch_version</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_sdpa_available</span><span class="p">():</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_torch_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">elif</span> <span class="n">_torch_version</span> <span class="o">==</span> <span class="s2">&quot;N/A&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="c1"># NOTE: MLU is OK with non-contiguous inputs.</span>
    <span class="k">if</span> <span class="n">is_torch_mlu_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="c1"># NOTE: NPU can use SDPA in Transformers with torch&gt;=2.1.0.</span>
    <span class="k">if</span> <span class="n">is_torch_npu_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="c1"># NOTE: We require torch&gt;=2.1.1 to avoid a numerical issue in SDPA with non-contiguous inputs: https://github.com/pytorch/pytorch/issues/112577</span>
    <span class="k">return</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">_torch_version</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s2">&quot;2.1.1&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_flex_attn_available</span><span class="p">():</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_torch_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">elif</span> <span class="n">_torch_version</span> <span class="o">==</span> <span class="s2">&quot;N/A&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="c1"># TODO check if some bugs cause push backs on the exact version</span>
    <span class="c1"># NOTE: We require torch&gt;=2.5.0 as it is the first release</span>
    <span class="k">return</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">_torch_version</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s2">&quot;2.5.0&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torchvision_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_torchvision_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torchvision_v2_available</span><span class="p">():</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_torchvision_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="c1"># NOTE: We require torchvision&gt;=0.15 as v2 transforms are available from this version: https://pytorch.org/vision/stable/transforms.html#v1-or-v2-which-one-should-i-use</span>
    <span class="k">return</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">_torchvision_version</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s2">&quot;0.15&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_galore_torch_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_galore_torch_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_apollo_torch_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_apollo_torch_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_lomo_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_lomo_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_grokadamw_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_grokadamw_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_schedulefree_available</span><span class="p">(</span><span class="n">min_version</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">SCHEDULEFREE_MIN_VERSION</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">_schedulefree_available</span> <span class="ow">and</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">_schedulefree_version</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">min_version</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_pyctcdecode_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_pyctcdecode_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_librosa_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_librosa_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_essentia_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_essentia_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_pretty_midi_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_pretty_midi_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_cuda_available</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">is_torch_available</span><span class="p">():</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_mamba_ssm_available</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">is_torch_available</span><span class="p">():</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;mamba_ssm&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_mamba_2_ssm_available</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">is_torch_available</span><span class="p">():</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;mamba_ssm&quot;</span><span class="p">):</span>
                <span class="kn">import</span><span class="w"> </span><span class="nn">mamba_ssm</span>

                <span class="k">if</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">mamba_ssm</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s2">&quot;2.0.4&quot;</span><span class="p">):</span>
                    <span class="k">return</span> <span class="kc">True</span>
    <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_causal_conv1d_available</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">is_torch_available</span><span class="p">():</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;causal_conv1d&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_mambapy_available</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">is_torch_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;mambapy&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_mps_available</span><span class="p">(</span><span class="n">min_version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">is_torch_available</span><span class="p">():</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="p">,</span> <span class="s2">&quot;mps&quot;</span><span class="p">):</span>
            <span class="n">backend_available</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_built</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">min_version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">flag</span> <span class="o">=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">_torch_version</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">min_version</span><span class="p">)</span>
                <span class="n">backend_available</span> <span class="o">=</span> <span class="n">backend_available</span> <span class="ow">and</span> <span class="n">flag</span>
            <span class="k">return</span> <span class="n">backend_available</span>
    <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_bf16_gpu_available</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_torch_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_bf16_supported</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">is_torch_xpu_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">xpu</span><span class="o">.</span><span class="n">is_bf16_supported</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">is_torch_hpu_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">if</span> <span class="n">is_torch_npu_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">npu</span><span class="o">.</span><span class="n">is_bf16_supported</span><span class="p">()</span>
    <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_bf16_cpu_available</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">is_torch_available</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_bf16_available</span><span class="p">():</span>
    <span class="c1"># the original bf16 check was for gpu only, but later a cpu/bf16 combo has emerged so this util</span>
    <span class="c1"># has become ambiguous and therefore deprecated</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
        <span class="s2">&quot;The util is_torch_bf16_available is deprecated, please use is_torch_bf16_gpu_available &quot;</span>
        <span class="s2">&quot;or is_torch_bf16_cpu_available instead according to whether it&#39;s used with cpu or gpu&quot;</span><span class="p">,</span>
        <span class="ne">FutureWarning</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">is_torch_bf16_gpu_available</span><span class="p">()</span>


<span class="nd">@lru_cache</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_fp16_available_on_device</span><span class="p">(</span><span class="n">device</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_torch_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">if</span> <span class="n">is_torch_hpu_available</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">is_habana_gaudi1</span><span class="p">():</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>

    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">x</span>

        <span class="c1"># At this moment, let&#39;s be strict of the check: check if `LayerNorm` is also supported on device, because many</span>
        <span class="c1"># models use this layer.</span>
        <span class="n">batch</span><span class="p">,</span> <span class="n">sentence_length</span><span class="p">,</span> <span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span>
        <span class="n">embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">sentence_length</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">layer_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">layer_norm</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>

    <span class="k">except</span><span class="p">:</span>  <span class="c1"># noqa: E722</span>
        <span class="c1"># TODO: more precise exception matching, if possible.</span>
        <span class="c1"># most backends should return `RuntimeError` however this is not guaranteed.</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">return</span> <span class="kc">True</span>


<span class="nd">@lru_cache</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_bf16_available_on_device</span><span class="p">(</span><span class="n">device</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_torch_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

    <span class="k">if</span> <span class="n">device</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">is_torch_bf16_gpu_available</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">device</span> <span class="o">==</span> <span class="s2">&quot;hpu&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">x</span>
    <span class="k">except</span><span class="p">:</span>  <span class="c1"># noqa: E722</span>
        <span class="c1"># TODO: more precise exception matching, if possible.</span>
        <span class="c1"># most backends should return `RuntimeError` however this is not guaranteed.</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">return</span> <span class="kc">True</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_tf32_available</span><span class="p">():</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_torch_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">cuda</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_properties</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">())</span><span class="o">.</span><span class="n">major</span> <span class="o">&lt;</span> <span class="mi">8</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="kc">True</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_fx_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">is_torch_available</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_peft_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_peft_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_bs4_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_bs4_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_tf_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_tf_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_coloredlogs_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_coloredlogs_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_tf2onnx_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_tf2onnx_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_onnx_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_onnx_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_openai_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_openai_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_flax_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_flax_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_flute_available</span><span class="p">():</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;flute&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;flute-kernel&quot;</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="s2">&quot;0.4.1&quot;</span>
    <span class="k">except</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">PackageNotFoundError</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_ftfy_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_ftfy_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_g2p_en_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_g2p_en_available</span>


<span class="nd">@lru_cache</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_xla_available</span><span class="p">(</span><span class="n">check_is_tpu</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">check_is_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check if `torch_xla` is available. To train a native pytorch job in an environment with torch xla installed, set</span>
<span class="sd">    the USE_TORCH_XLA to false.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="p">(</span><span class="n">check_is_tpu</span> <span class="ow">and</span> <span class="n">check_is_gpu</span><span class="p">),</span> <span class="s2">&quot;The check_is_tpu and check_is_gpu cannot both be true.&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">_torch_xla_available</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="kn">import</span><span class="w"> </span><span class="nn">torch_xla</span>

    <span class="k">if</span> <span class="n">check_is_gpu</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch_xla</span><span class="o">.</span><span class="n">runtime</span><span class="o">.</span><span class="n">device_type</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;GPU&quot;</span><span class="p">,</span> <span class="s2">&quot;CUDA&quot;</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">check_is_tpu</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch_xla</span><span class="o">.</span><span class="n">runtime</span><span class="o">.</span><span class="n">device_type</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;TPU&quot;</span>

    <span class="k">return</span> <span class="kc">True</span>


<span class="nd">@lru_cache</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_neuroncore_available</span><span class="p">(</span><span class="n">check_device</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;torch_neuronx&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">is_torch_xla_available</span><span class="p">()</span>
    <span class="k">return</span> <span class="kc">False</span>


<span class="nd">@lru_cache</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_npu_available</span><span class="p">(</span><span class="n">check_device</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="s2">&quot;Checks if `torch_npu` is installed and potentially if a NPU is in the environment&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_torch_available</span> <span class="ow">or</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;torch_npu&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torch_npu</span>  <span class="c1"># noqa: F401</span>

    <span class="k">if</span> <span class="n">check_device</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Will raise a RuntimeError if no NPU is found</span>
            <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">npu</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">npu</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;npu&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">npu</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>


<span class="nd">@lru_cache</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_mlu_available</span><span class="p">(</span><span class="n">check_device</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Checks if `mlu` is available via an `cndev-based` check which won&#39;t trigger the drivers and leave mlu</span>
<span class="sd">    uninitialized.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_torch_available</span> <span class="ow">or</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;torch_mlu&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torch_mlu</span>  <span class="c1"># noqa: F401</span>

    <span class="n">pytorch_cndev_based_mlu_check_previous_value</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;PYTORCH_CNDEV_BASED_MLU_CHECK&quot;</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;PYTORCH_CNDEV_BASED_MLU_CHECK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">available</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mlu</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">pytorch_cndev_based_mlu_check_previous_value</span><span class="p">:</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;PYTORCH_CNDEV_BASED_MLU_CHECK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pytorch_cndev_based_mlu_check_previous_value</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;PYTORCH_CNDEV_BASED_MLU_CHECK&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">available</span>


<span class="nd">@lru_cache</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_musa_available</span><span class="p">(</span><span class="n">check_device</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="s2">&quot;Checks if `torch_musa` is installed and potentially if a MUSA is in the environment&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_torch_available</span> <span class="ow">or</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;torch_musa&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torch_musa</span>  <span class="c1"># noqa: F401</span>

    <span class="n">torch_musa_min_version</span> <span class="o">=</span> <span class="s2">&quot;0.33.0&quot;</span>
    <span class="k">if</span> <span class="n">_accelerate_available</span> <span class="ow">and</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">_accelerate_version</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">torch_musa_min_version</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">if</span> <span class="n">check_device</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Will raise a RuntimeError if no MUSA is found</span>
            <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">musa</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">musa</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;musa&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">musa</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>


<span class="nd">@lru_cache</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_hpu_available</span><span class="p">():</span>
    <span class="s2">&quot;Checks if `torch.hpu` is available and potentially if a HPU is in the environment&quot;</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="ow">not</span> <span class="n">_torch_available</span>
        <span class="ow">or</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;habana_frameworks&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="ow">or</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;habana_frameworks.torch&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span>
    <span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="n">torch_hpu_min_version</span> <span class="o">=</span> <span class="s2">&quot;1.5.0&quot;</span>
    <span class="k">if</span> <span class="n">_accelerate_available</span> <span class="ow">and</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">_accelerate_version</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">torch_hpu_min_version</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;PT_HPU_LAZY_MODE&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;1&quot;</span><span class="p">:</span>
        <span class="c1"># import habana_frameworks.torch in case of lazy mode to patch torch with torch.hpu</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">habana_frameworks.torch</span>  <span class="c1"># noqa: F401</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;hpu&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">hpu</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="kn">import</span><span class="w"> </span><span class="nn">habana_frameworks.torch.utils.experimental</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">htexp</span>  <span class="c1"># noqa: F401</span>

    <span class="c1"># IlyasMoutawwakil: We patch masked_fill_ for int64 tensors to avoid a bug on Gaudi1</span>
    <span class="c1"># synNodeCreateWithId failed for node: masked_fill_fwd_i64 with synStatus 26 [Generic failure]</span>
    <span class="c1"># This can be removed once Gaudi1 support is discontinued but for now we need it to keep using</span>
    <span class="c1"># dl1.24xlarge Gaudi1 instances on AWS for testing.</span>
    <span class="c1"># check if the device is Gaudi1 (vs Gaudi2, Gaudi3).</span>
    <span class="k">if</span> <span class="n">htexp</span><span class="o">.</span><span class="n">_get_device_type</span><span class="p">()</span> <span class="o">==</span> <span class="n">htexp</span><span class="o">.</span><span class="n">synDeviceType</span><span class="o">.</span><span class="n">synDeviceGaudi</span><span class="p">:</span>
        <span class="n">original_masked_fill_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">.</span><span class="n">masked_fill_</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">patched_masked_fill_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning_once</span><span class="p">(</span>
                    <span class="s2">&quot;In-place tensor.masked_fill_(mask, value) is not supported for int64 tensors on Gaudi1. &quot;</span>
                    <span class="s2">&quot;This operation will be performed out-of-place using tensor[mask] = value.&quot;</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">original_masked_fill_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">.</span><span class="n">masked_fill_</span> <span class="o">=</span> <span class="n">patched_masked_fill_</span>

    <span class="k">return</span> <span class="kc">True</span>


<span class="nd">@lru_cache</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_habana_gaudi1</span><span class="p">():</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_torch_hpu_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="kn">import</span><span class="w"> </span><span class="nn">habana_frameworks.torch.utils.experimental</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">htexp</span>  <span class="c1"># noqa: F401</span>

    <span class="c1"># Check if the device is Gaudi1 (vs Gaudi2, Gaudi3)</span>
    <span class="k">return</span> <span class="n">htexp</span><span class="o">.</span><span class="n">_get_device_type</span><span class="p">()</span> <span class="o">==</span> <span class="n">htexp</span><span class="o">.</span><span class="n">synDeviceType</span><span class="o">.</span><span class="n">synDeviceGaudi</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torchdynamo_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">is_torch_available</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_compile_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">is_torch_available</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torchdynamo_compiling</span><span class="p">():</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_torch_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="c1"># Importing torch._dynamo causes issues with PyTorch profiler (https://github.com/pytorch/pytorch/issues/130622)</span>
    <span class="c1"># hence rather relying on `torch.compiler.is_compiling()` when possible (torch&gt;=2.3)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">compiler</span><span class="o">.</span><span class="n">is_compiling</span><span class="p">()</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">torch._dynamo</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dynamo</span>  <span class="c1"># noqa: F401</span>

            <span class="k">return</span> <span class="n">dynamo</span><span class="o">.</span><span class="n">is_compiling</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torchdynamo_exporting</span><span class="p">():</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_torch_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">compiler</span><span class="o">.</span><span class="n">is_exporting</span><span class="p">()</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">torch._dynamo</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dynamo</span>  <span class="c1"># noqa: F401</span>

            <span class="k">return</span> <span class="n">dynamo</span><span class="o">.</span><span class="n">is_exporting</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_tensorrt_fx_available</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;torch_tensorrt&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;torch_tensorrt.fx&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_datasets_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_datasets_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_detectron2_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_detectron2_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_rjieba_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_rjieba_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_psutil_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_psutil_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_py3nvml_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_py3nvml_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_sacremoses_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_sacremoses_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_apex_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_apex_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_aqlm_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_aqlm_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_vptq_available</span><span class="p">(</span><span class="n">min_version</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">VPTQ_MIN_VERSION</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">_vptq_available</span> <span class="ow">and</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">_vptq_version</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">min_version</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_av_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_av_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_decord_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_decord_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_ninja_available</span><span class="p">():</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Code comes from *torch.utils.cpp_extension.is_ninja_available()*. Returns `True` if the</span>
<span class="sd">    [ninja](https://ninja-build.org/) build system is available on the system, `False` otherwise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">subprocess</span><span class="o">.</span><span class="n">check_output</span><span class="p">(</span><span class="s2">&quot;ninja --version&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_ipex_available</span><span class="p">(</span><span class="n">min_version</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_major_and_minor_from_version</span><span class="p">(</span><span class="n">full_version</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">full_version</span><span class="p">)</span><span class="o">.</span><span class="n">major</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;.&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">full_version</span><span class="p">)</span><span class="o">.</span><span class="n">minor</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_torch_available</span><span class="p">()</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">_ipex_available</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="n">torch_major_and_minor</span> <span class="o">=</span> <span class="n">get_major_and_minor_from_version</span><span class="p">(</span><span class="n">_torch_version</span><span class="p">)</span>
    <span class="n">ipex_major_and_minor</span> <span class="o">=</span> <span class="n">get_major_and_minor_from_version</span><span class="p">(</span><span class="n">_ipex_version</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">torch_major_and_minor</span> <span class="o">!=</span> <span class="n">ipex_major_and_minor</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Intel Extension for PyTorch </span><span class="si">{</span><span class="n">ipex_major_and_minor</span><span class="si">}</span><span class="s2"> needs to work with PyTorch </span><span class="si">{</span><span class="n">ipex_major_and_minor</span><span class="si">}</span><span class="s2">.*,&quot;</span>
            <span class="sa">f</span><span class="s2">&quot; but PyTorch </span><span class="si">{</span><span class="n">_torch_version</span><span class="si">}</span><span class="s2"> is found. Please switch to the matching version and run again.&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="n">min_version</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">_ipex_version</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">min_version</span><span class="p">)</span>
    <span class="k">return</span> <span class="kc">True</span>


<span class="nd">@lru_cache</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_xpu_available</span><span class="p">(</span><span class="n">check_device</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Checks if XPU acceleration is available either via native PyTorch (&gt;=2.6),</span>
<span class="sd">    `intel_extension_for_pytorch` or via stock PyTorch (&gt;=2.4) and potentially</span>
<span class="sd">    if a XPU is in the environment.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_torch_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="n">torch_version</span> <span class="o">=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">_torch_version</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">torch_version</span><span class="o">.</span><span class="n">major</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">torch_version</span><span class="o">.</span><span class="n">minor</span> <span class="o">&lt;</span> <span class="mi">6</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">is_ipex_available</span><span class="p">():</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">intel_extension_for_pytorch</span>  <span class="c1"># noqa: F401</span>
        <span class="k">elif</span> <span class="n">torch_version</span><span class="o">.</span><span class="n">major</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">torch_version</span><span class="o">.</span><span class="n">minor</span> <span class="o">&lt;</span> <span class="mi">4</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

    <span class="k">if</span> <span class="n">check_device</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Will raise a RuntimeError if no XPU  is found</span>
            <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">xpu</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">xpu</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;xpu&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">xpu</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>


<span class="nd">@lru_cache</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_bitsandbytes_available</span><span class="p">():</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_torch_available</span><span class="p">()</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">_bitsandbytes_available</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

    <span class="c1"># `bitsandbytes` versions older than 0.43.1 eagerly require CUDA at import time,</span>
    <span class="c1"># so those versions of the library are practically only available when CUDA is too.</span>
    <span class="k">if</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;bitsandbytes&quot;</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s2">&quot;0.43.1&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>

    <span class="c1"># Newer versions of `bitsandbytes` can be imported on systems without CUDA.</span>
    <span class="k">return</span> <span class="kc">True</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_bitsandbytes_multi_backend_available</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_bitsandbytes_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="kn">import</span><span class="w"> </span><span class="nn">bitsandbytes</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">bnb</span>

    <span class="k">return</span> <span class="s2">&quot;multi_backend&quot;</span> <span class="ow">in</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">bnb</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="nb">set</span><span class="p">())</span>


<div class="viewcode-block" id="is_flash_attn_2_available">
<a class="viewcode-back" href="../../../api/src.training.utils.html#src.training.utils.hierarchical_grpo_dependencies.is_flash_attn_2_available">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">is_flash_attn_2_available</span><span class="p">():</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_torch_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;flash_attn&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="c1"># Let&#39;s add an extra check to see if cuda is available</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">or</span> <span class="n">is_torch_mlu_available</span><span class="p">()):</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">cuda</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;flash_attn&quot;</span><span class="p">))</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s2">&quot;2.1.0&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">torch</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">hip</span><span class="p">:</span>
        <span class="c1"># TODO: Bump the requirement to 2.1.0 once released in https://github.com/ROCmSoftwarePlatform/flash-attention</span>
        <span class="k">return</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;flash_attn&quot;</span><span class="p">))</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s2">&quot;2.0.4&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">is_torch_mlu_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;flash_attn&quot;</span><span class="p">))</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s2">&quot;2.3.3&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span></div>



<span class="nd">@lru_cache</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_flash_attn_greater_or_equal_2_10</span><span class="p">():</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;flash_attn&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">return</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;flash_attn&quot;</span><span class="p">))</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s2">&quot;2.1.0&quot;</span><span class="p">)</span>


<span class="nd">@lru_cache</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_flash_attn_greater_or_equal</span><span class="p">(</span><span class="n">library_version</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;flash_attn&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">return</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;flash_attn&quot;</span><span class="p">))</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">library_version</span><span class="p">)</span>


<span class="nd">@lru_cache</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_greater_or_equal</span><span class="p">(</span><span class="n">library_version</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">accept_dev</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Accepts a library version and returns True if the current version of the library is greater than or equal to the</span>
<span class="sd">    given version. If `accept_dev` is True, it will also accept development versions (e.g. 2.7.0.dev20250320 matches</span>
<span class="sd">    2.7.0).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;torch&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">if</span> <span class="n">accept_dev</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;torch&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">base_version</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span>
            <span class="n">library_version</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;torch&quot;</span><span class="p">))</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">library_version</span><span class="p">)</span>


<span class="nd">@lru_cache</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_huggingface_hub_greater_or_equal</span><span class="p">(</span><span class="n">library_version</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">accept_dev</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;huggingface_hub&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">if</span> <span class="n">accept_dev</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span>
            <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;huggingface_hub&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">base_version</span>
        <span class="p">)</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">library_version</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;huggingface_hub&quot;</span><span class="p">))</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">library_version</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torchdistx_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_torchdistx_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_faiss_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_faiss_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_scipy_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_scipy_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_sklearn_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_sklearn_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_sentencepiece_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_sentencepiece_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_seqio_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_is_seqio_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_gguf_available</span><span class="p">(</span><span class="n">min_version</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">GGUF_MIN_VERSION</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">_is_gguf_available</span> <span class="ow">and</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">_gguf_version</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">min_version</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_protobuf_available</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;google&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;google.protobuf&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_fsdp_available</span><span class="p">(</span><span class="n">min_version</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">FSDP_MIN_VERSION</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">is_torch_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">_torch_version</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">min_version</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_optimum_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_optimum_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_auto_awq_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_auto_awq_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_auto_round_available</span><span class="p">(</span><span class="n">min_version</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">AUTOROUND_MIN_VERSION</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">_auto_round_available</span> <span class="ow">and</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">_auto_round_version</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">min_version</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_optimum_quanto_available</span><span class="p">():</span>
    <span class="c1"># `importlib.metadata.version` doesn&#39;t work with `optimum.quanto`, need to put `optimum_quanto`</span>
    <span class="k">return</span> <span class="n">_is_optimum_quanto_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_quark_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_quark_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_compressed_tensors_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_compressed_tensors_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_auto_gptq_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_auto_gptq_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_gptqmodel_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_gptqmodel_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_eetq_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_eetq_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_fbgemm_gpu_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_fbgemm_gpu_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_levenshtein_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_levenshtein_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_optimum_neuron_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_optimum_available</span> <span class="ow">and</span> <span class="n">_is_package_available</span><span class="p">(</span><span class="s2">&quot;optimum.neuron&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_safetensors_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_safetensors_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_tokenizers_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_tokenizers_available</span>


<span class="nd">@lru_cache</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_vision_available</span><span class="p">():</span>
    <span class="n">_pil_available</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;PIL&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">_pil_available</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">package_version</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;Pillow&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">PackageNotFoundError</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">package_version</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;Pillow-SIMD&quot;</span><span class="p">)</span>
            <span class="k">except</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">PackageNotFoundError</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Detected PIL version </span><span class="si">{</span><span class="n">package_version</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_pil_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_pytesseract_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_pytesseract_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_pytest_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_pytest_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_spacy_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_spacy_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_tensorflow_text_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">is_tf_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">_tensorflow_text_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_keras_nlp_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">is_tensorflow_text_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">_keras_nlp_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_in_notebook</span><span class="p">():</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Check if we are running inside Marimo</span>
        <span class="k">if</span> <span class="s2">&quot;marimo&quot;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="c1"># Test adapted from tqdm.autonotebook: https://github.com/tqdm/tqdm/blob/master/tqdm/autonotebook.py</span>
        <span class="n">get_ipython</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="s2">&quot;IPython&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">get_ipython</span>
        <span class="k">if</span> <span class="s2">&quot;IPKernelApp&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">config</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;console&quot;</span><span class="p">)</span>
        <span class="c1"># Removed the lines to include VSCode</span>
        <span class="k">if</span> <span class="s2">&quot;DATABRICKS_RUNTIME_VERSION&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;DATABRICKS_RUNTIME_VERSION&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="s2">&quot;11.0&quot;</span><span class="p">:</span>
            <span class="c1"># Databricks Runtime 11.0 and above uses IPython kernel by default so it should be compatible with Jupyter notebook</span>
            <span class="c1"># https://docs.microsoft.com/en-us/azure/databricks/notebooks/ipython-kernel</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;databricks&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;IPython&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">except</span> <span class="p">(</span><span class="ne">AttributeError</span><span class="p">,</span> <span class="ne">ImportError</span><span class="p">,</span> <span class="ne">KeyError</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_pytorch_quantization_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_pytorch_quantization_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_tensorflow_probability_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_tensorflow_probability_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_pandas_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_pandas_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_sagemaker_dp_enabled</span><span class="p">():</span>
    <span class="c1"># Get the sagemaker specific env variable.</span>
    <span class="n">sagemaker_params</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;SM_FRAMEWORK_PARAMS&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Parse it and check the field &quot;sagemaker_distributed_dataparallel_enabled&quot;.</span>
        <span class="n">sagemaker_params</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">sagemaker_params</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">sagemaker_params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;sagemaker_distributed_dataparallel_enabled&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
    <span class="k">except</span> <span class="n">json</span><span class="o">.</span><span class="n">JSONDecodeError</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="c1"># Lastly, check if the `smdistributed` module is present.</span>
    <span class="k">return</span> <span class="n">_smdistributed_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_sagemaker_mp_enabled</span><span class="p">():</span>
    <span class="c1"># Get the sagemaker specific mp parameters from smp_options variable.</span>
    <span class="n">smp_options</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;SM_HP_MP_PARAMETERS&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Parse it and check the field &quot;partitions&quot; is included, it is required for model parallel.</span>
        <span class="n">smp_options</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">smp_options</span><span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;partitions&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">smp_options</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
    <span class="k">except</span> <span class="n">json</span><span class="o">.</span><span class="n">JSONDecodeError</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="c1"># Get the sagemaker specific framework parameters from mpi_options variable.</span>
    <span class="n">mpi_options</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;SM_FRAMEWORK_PARAMS&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Parse it and check the field &quot;sagemaker_distributed_dataparallel_enabled&quot;.</span>
        <span class="n">mpi_options</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">mpi_options</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">mpi_options</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;sagemaker_mpi_enabled&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
    <span class="k">except</span> <span class="n">json</span><span class="o">.</span><span class="n">JSONDecodeError</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="c1"># Lastly, check if the `smdistributed` module is present.</span>
    <span class="k">return</span> <span class="n">_smdistributed_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_training_run_on_sagemaker</span><span class="p">():</span>
    <span class="k">return</span> <span class="s2">&quot;SAGEMAKER_JOB_NAME&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_soundfile_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_soundfile_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_timm_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_timm_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_natten_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_natten_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_nltk_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_nltk_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torchaudio_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_torchaudio_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torchao_available</span><span class="p">(</span><span class="n">min_version</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">TORCHAO_MIN_VERSION</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">_torchao_available</span> <span class="ow">and</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">_torchao_version</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">min_version</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_speech_available</span><span class="p">():</span>
    <span class="c1"># For now this depends on torchaudio but the exact dependency might evolve in the future.</span>
    <span class="k">return</span> <span class="n">_torchaudio_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_spqr_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_spqr_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_phonemizer_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_phonemizer_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_uroman_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_uroman_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">torch_only_method</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">wrapper</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_torch_available</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                <span class="s2">&quot;You need to install pytorch to use this method or class, &quot;</span>
                <span class="s2">&quot;or activate it with environment variables USE_TORCH=1 and USE_TF=0.&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">wrapper</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_ccl_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_is_ccl_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_sudachi_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_sudachipy_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_sudachi_version</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_sudachipy_version</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_sudachi_projection_available</span><span class="p">():</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_sudachi_available</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="c1"># NOTE: We require sudachipy&gt;=0.6.8 to use projection option in sudachi_kwargs for the constructor of BertJapaneseTokenizer.</span>
    <span class="c1"># - `projection` option is not supported in sudachipy&lt;0.6.8, see https://github.com/WorksApplications/sudachi.rs/issues/230</span>
    <span class="k">return</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">_sudachipy_version</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s2">&quot;0.6.8&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_jumanpp_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;rhoknp&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">shutil</span><span class="o">.</span><span class="n">which</span><span class="p">(</span><span class="s2">&quot;jumanpp&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_cython_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s2">&quot;pyximport&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_jieba_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_jieba_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_jinja_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_jinja_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_mlx_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_mlx_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_num2words_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_num2words_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_tiktoken_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_tiktoken_available</span> <span class="ow">and</span> <span class="n">_blobfile_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_liger_kernel_available</span><span class="p">():</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_liger_kernel_available</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">return</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;liger_kernel&quot;</span><span class="p">))</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s2">&quot;0.3.0&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_triton_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_triton_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_rich_available</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">_rich_available</span>


<span class="k">def</span><span class="w"> </span><span class="nf">check_torch_load_is_safe</span><span class="p">():</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_torch_greater_or_equal</span><span class="p">(</span><span class="s2">&quot;2.6&quot;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users &quot;</span>
            <span class="s2">&quot;to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply &quot;</span>
            <span class="s2">&quot;when loading files with safetensors.&quot;</span>
            <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434&quot;</span>
        <span class="p">)</span>


<span class="c1"># docstyle-ignore</span>
<span class="n">AV_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the PyAv library but it was not found in your environment. You can install it with:</span>
<span class="s2">```</span>
<span class="s2">pip install av</span>
<span class="s2">```</span>
<span class="s2">Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">YT_DLP_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the YT-DLP library but it was not found in your environment. You can install it with:</span>
<span class="s2">```</span>
<span class="s2">pip install yt-dlp</span>
<span class="s2">```</span>
<span class="s2">Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="n">DECORD_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the PyAv library but it was not found in your environment. You can install it with:</span>
<span class="s2">```</span>
<span class="s2">pip install decord</span>
<span class="s2">```</span>
<span class="s2">Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">CV2_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the OpenCV library but it was not found in your environment. You can install it with:</span>
<span class="s2">```</span>
<span class="s2">pip install opencv-python</span>
<span class="s2">```</span>
<span class="s2">Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>


<span class="c1"># docstyle-ignore</span>
<span class="n">DATASETS_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the  Datasets library but it was not found in your environment. You can install it with:</span>
<span class="s2">```</span>
<span class="s2">pip install datasets</span>
<span class="s2">```</span>
<span class="s2">In a notebook or a colab, you can install it by executing a cell with</span>
<span class="s2">```</span>
<span class="s2">!pip install datasets</span>
<span class="s2">```</span>
<span class="s2">then restarting your kernel.</span>

<span class="s2">Note that if you have a local folder named `datasets` or a local python file named `datasets.py` in your current</span>
<span class="s2">working directory, python may try to import this instead of the  Datasets library. You should rename this folder or</span>
<span class="s2">that python file if that&#39;s the case. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>


<span class="c1"># docstyle-ignore</span>
<span class="n">TOKENIZERS_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the  Tokenizers library but it was not found in your environment. You can install it with:</span>
<span class="s2">```</span>
<span class="s2">pip install tokenizers</span>
<span class="s2">```</span>
<span class="s2">In a notebook or a colab, you can install it by executing a cell with</span>
<span class="s2">```</span>
<span class="s2">!pip install tokenizers</span>
<span class="s2">```</span>
<span class="s2">Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>


<span class="c1"># docstyle-ignore</span>
<span class="n">SENTENCEPIECE_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the</span>
<span class="s2">installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones</span>
<span class="s2">that match your environment. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>


<span class="c1"># docstyle-ignore</span>
<span class="n">PROTOBUF_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the protobuf library but it was not found in your environment. Checkout the instructions on the</span>
<span class="s2">installation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones</span>
<span class="s2">that match your environment. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>


<span class="c1"># docstyle-ignore</span>
<span class="n">FAISS_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the faiss library but it was not found in your environment. Checkout the instructions on the</span>
<span class="s2">installation page of its repo: https://github.com/facebookresearch/faiss/blob/master/INSTALL.md and follow the ones</span>
<span class="s2">that match your environment. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>


<span class="c1"># docstyle-ignore</span>
<span class="n">PYTORCH_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the PyTorch library but it was not found in your environment. Checkout the instructions on the</span>
<span class="s2">installation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.</span>
<span class="s2">Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>


<span class="c1"># docstyle-ignore</span>
<span class="n">TORCHVISION_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the Torchvision library but it was not found in your environment. Checkout the instructions on the</span>
<span class="s2">installation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.</span>
<span class="s2">Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">PYTORCH_IMPORT_ERROR_WITH_TF</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the PyTorch library but it was not found in your environment.</span>
<span class="s2">However, we were able to find a TensorFlow installation. TensorFlow classes begin</span>
<span class="s2">with &quot;TF&quot;, but are otherwise identically named to our PyTorch classes. This</span>
<span class="s2">means that the TF equivalent of the class you tried to import would be &quot;TF</span><span class="si">{0}</span><span class="s2">&quot;.</span>
<span class="s2">If you want to use TensorFlow, please use TF classes instead!</span>

<span class="s2">If you really do want to use PyTorch please go to</span>
<span class="s2">https://pytorch.org/get-started/locally/ and follow the instructions that</span>
<span class="s2">match your environment.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">TF_IMPORT_ERROR_WITH_PYTORCH</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the TensorFlow library but it was not found in your environment.</span>
<span class="s2">However, we were able to find a PyTorch installation. PyTorch classes do not begin</span>
<span class="s2">with &quot;TF&quot;, but are otherwise identically named to our TF classes.</span>
<span class="s2">If you want to use PyTorch, please use those classes instead!</span>

<span class="s2">If you really do want to use TensorFlow, please follow the instructions on the</span>
<span class="s2">installation page https://www.tensorflow.org/install that match your environment.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">BS4_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the Beautiful Soup library but it was not found in your environment. You can install it with pip:</span>
<span class="s2">`pip install beautifulsoup4`. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>


<span class="c1"># docstyle-ignore</span>
<span class="n">SKLEARN_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the scikit-learn library but it was not found in your environment. You can install it with:</span>
<span class="s2">```</span>
<span class="s2">pip install -U scikit-learn</span>
<span class="s2">```</span>
<span class="s2">In a notebook or a colab, you can install it by executing a cell with</span>
<span class="s2">```</span>
<span class="s2">!pip install -U scikit-learn</span>
<span class="s2">```</span>
<span class="s2">Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>


<span class="c1"># docstyle-ignore</span>
<span class="n">TENSORFLOW_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the TensorFlow library but it was not found in your environment. Checkout the instructions on the</span>
<span class="s2">installation page: https://www.tensorflow.org/install and follow the ones that match your environment.</span>
<span class="s2">Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>


<span class="c1"># docstyle-ignore</span>
<span class="n">DETECTRON2_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the detectron2 library but it was not found in your environment. Checkout the instructions on the</span>
<span class="s2">installation page: https://github.com/facebookresearch/detectron2/blob/master/INSTALL.md and follow the ones</span>
<span class="s2">that match your environment. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>


<span class="c1"># docstyle-ignore</span>
<span class="n">FLAX_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the FLAX library but it was not found in your environment. Checkout the instructions on the</span>
<span class="s2">installation page: https://github.com/google/flax and follow the ones that match your environment.</span>
<span class="s2">Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">FTFY_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the ftfy library but it was not found in your environment. Checkout the instructions on the</span>
<span class="s2">installation section: https://github.com/rspeer/python-ftfy/tree/master#installing and follow the ones</span>
<span class="s2">that match your environment. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="n">LEVENSHTEIN_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the python-Levenshtein library but it was not found in your environment. You can install it with pip: `pip</span>
<span class="s2">install python-Levenshtein`. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">G2P_EN_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the g2p-en library but it was not found in your environment. You can install it with pip:</span>
<span class="s2">`pip install g2p-en`. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">PYTORCH_QUANTIZATION_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the pytorch-quantization library but it was not found in your environment. You can install it with pip:</span>
<span class="s2">`pip install pytorch-quantization --extra-index-url https://pypi.ngc.nvidia.com`</span>
<span class="s2">Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">TENSORFLOW_PROBABILITY_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the tensorflow_probability library but it was not found in your environment. You can install it with pip as</span>
<span class="s2">explained here: https://github.com/tensorflow/probability. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">TENSORFLOW_TEXT_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the tensorflow_text library but it was not found in your environment. You can install it with pip as</span>
<span class="s2">explained here: https://www.tensorflow.org/text/guide/tf_text_intro.</span>
<span class="s2">Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">TORCHAUDIO_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the torchaudio library but it was not found in your environment. Please install it and restart your</span>
<span class="s2">runtime.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">PANDAS_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the pandas library but it was not found in your environment. You can install it with pip as</span>
<span class="s2">explained here: https://pandas.pydata.org/pandas-docs/stable/getting_started/install.html.</span>
<span class="s2">Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>


<span class="c1"># docstyle-ignore</span>
<span class="n">PHONEMIZER_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the phonemizer library but it was not found in your environment. You can install it with pip:</span>
<span class="s2">`pip install phonemizer`. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>
<span class="c1"># docstyle-ignore</span>
<span class="n">UROMAN_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the uroman library but it was not found in your environment. You can install it with pip:</span>
<span class="s2">`pip install uroman`. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>


<span class="c1"># docstyle-ignore</span>
<span class="n">SACREMOSES_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the sacremoses library but it was not found in your environment. You can install it with pip:</span>
<span class="s2">`pip install sacremoses`. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">SCIPY_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the scipy library but it was not found in your environment. You can install it with pip:</span>
<span class="s2">`pip install scipy`. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">KERAS_NLP_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the keras_nlp library but it was not found in your environment. You can install it with pip.</span>
<span class="s2">Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">SPEECH_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the torchaudio library but it was not found in your environment. You can install it with pip:</span>
<span class="s2">`pip install torchaudio`. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">TIMM_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the timm library but it was not found in your environment. You can install it with pip:</span>
<span class="s2">`pip install timm`. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">NATTEN_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the natten library but it was not found in your environment. You can install it by referring to:</span>
<span class="s2">shi-labs.com/natten . You can also install it with pip (may take longer to build):</span>
<span class="s2">`pip install natten`. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="n">NUMEXPR_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the numexpr library but it was not found in your environment. You can install it by referring to:</span>
<span class="s2">https://numexpr.readthedocs.io/en/latest/index.html.</span>
<span class="s2">&quot;&quot;&quot;</span>


<span class="c1"># docstyle-ignore</span>
<span class="n">NLTK_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the NLTK library but it was not found in your environment. You can install it by referring to:</span>
<span class="s2">https://www.nltk.org/install.html. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>


<span class="c1"># docstyle-ignore</span>
<span class="n">VISION_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the PIL library but it was not found in your environment. You can install it with pip:</span>
<span class="s2">`pip install pillow`. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>


<span class="c1"># docstyle-ignore</span>
<span class="n">PYTESSERACT_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the PyTesseract library but it was not found in your environment. You can install it with pip:</span>
<span class="s2">`pip install pytesseract`. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">PYCTCDECODE_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the pyctcdecode library but it was not found in your environment. You can install it with pip:</span>
<span class="s2">`pip install pyctcdecode`. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">ACCELERATE_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the accelerate library &gt;= </span><span class="si">{ACCELERATE_MIN_VERSION}</span><span class="s2"> it was not found in your environment.</span>
<span class="s2">You can install or update it with pip: `pip install --upgrade accelerate`. Please note that you may need to restart your</span>
<span class="s2">runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">CCL_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the torch ccl library but it was not found in your environment. You can install it with pip:</span>
<span class="s2">`pip install oneccl_bind_pt -f https://developer.intel.com/ipex-whl-stable`</span>
<span class="s2">Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">ESSENTIA_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires essentia library. But that was not found in your environment. You can install them with pip:</span>
<span class="s2">`pip install essentia==2.1b6.dev1034`</span>
<span class="s2">Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">LIBROSA_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the librosa library. But that was not found in your environment. You can install them with pip:</span>
<span class="s2">`pip install librosa`</span>
<span class="s2">Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># docstyle-ignore</span>
<span class="n">PRETTY_MIDI_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the pretty_midi library. But that was not found in your environment. You can install them with pip:</span>
<span class="s2">`pip install pretty_midi`</span>
<span class="s2">Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>


<span class="n">CYTHON_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the Cython library but it was not found in your environment. You can install it with pip: `pip install</span>
<span class="s2">Cython`. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="n">JIEBA_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the jieba library but it was not found in your environment. You can install it with pip: `pip install</span>
<span class="s2">jieba`. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="n">PEFT_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the peft library but it was not found in your environment. You can install it with pip: `pip install</span>
<span class="s2">peft`. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="n">JINJA_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the jinja library but it was not found in your environment. You can install it with pip: `pip install</span>
<span class="s2">jinja2`. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="n">RICH_IMPORT_ERROR</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="si">{0}</span><span class="s2"> requires the rich library but it was not found in your environment. You can install it with pip: `pip install</span>
<span class="s2">rich`. Please note that you may need to restart your runtime after installation.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="n">BACKENDS_MAPPING</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;av&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_av_available</span><span class="p">,</span> <span class="n">AV_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;bs4&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_bs4_available</span><span class="p">,</span> <span class="n">BS4_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;cv2&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_cv2_available</span><span class="p">,</span> <span class="n">CV2_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;datasets&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_datasets_available</span><span class="p">,</span> <span class="n">DATASETS_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;decord&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_decord_available</span><span class="p">,</span> <span class="n">DECORD_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;detectron2&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_detectron2_available</span><span class="p">,</span> <span class="n">DETECTRON2_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;essentia&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_essentia_available</span><span class="p">,</span> <span class="n">ESSENTIA_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;faiss&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_faiss_available</span><span class="p">,</span> <span class="n">FAISS_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;flax&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_flax_available</span><span class="p">,</span> <span class="n">FLAX_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;ftfy&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_ftfy_available</span><span class="p">,</span> <span class="n">FTFY_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;g2p_en&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_g2p_en_available</span><span class="p">,</span> <span class="n">G2P_EN_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;pandas&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_pandas_available</span><span class="p">,</span> <span class="n">PANDAS_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;phonemizer&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_phonemizer_available</span><span class="p">,</span> <span class="n">PHONEMIZER_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;uroman&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_uroman_available</span><span class="p">,</span> <span class="n">UROMAN_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;pretty_midi&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_pretty_midi_available</span><span class="p">,</span> <span class="n">PRETTY_MIDI_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;levenshtein&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_levenshtein_available</span><span class="p">,</span> <span class="n">LEVENSHTEIN_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;librosa&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_librosa_available</span><span class="p">,</span> <span class="n">LIBROSA_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;protobuf&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_protobuf_available</span><span class="p">,</span> <span class="n">PROTOBUF_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;pyctcdecode&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_pyctcdecode_available</span><span class="p">,</span> <span class="n">PYCTCDECODE_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;pytesseract&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_pytesseract_available</span><span class="p">,</span> <span class="n">PYTESSERACT_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;sacremoses&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_sacremoses_available</span><span class="p">,</span> <span class="n">SACREMOSES_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;pytorch_quantization&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_pytorch_quantization_available</span><span class="p">,</span> <span class="n">PYTORCH_QUANTIZATION_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;sentencepiece&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_sentencepiece_available</span><span class="p">,</span> <span class="n">SENTENCEPIECE_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;sklearn&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_sklearn_available</span><span class="p">,</span> <span class="n">SKLEARN_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;speech&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_speech_available</span><span class="p">,</span> <span class="n">SPEECH_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;tensorflow_probability&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_tensorflow_probability_available</span><span class="p">,</span> <span class="n">TENSORFLOW_PROBABILITY_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;tf&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_tf_available</span><span class="p">,</span> <span class="n">TENSORFLOW_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;tensorflow_text&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_tensorflow_text_available</span><span class="p">,</span> <span class="n">TENSORFLOW_TEXT_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;timm&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_timm_available</span><span class="p">,</span> <span class="n">TIMM_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;torchaudio&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_torchaudio_available</span><span class="p">,</span> <span class="n">TORCHAUDIO_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;natten&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_natten_available</span><span class="p">,</span> <span class="n">NATTEN_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;nltk&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_nltk_available</span><span class="p">,</span> <span class="n">NLTK_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;tokenizers&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_tokenizers_available</span><span class="p">,</span> <span class="n">TOKENIZERS_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_torch_available</span><span class="p">,</span> <span class="n">PYTORCH_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;torchvision&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_torchvision_available</span><span class="p">,</span> <span class="n">TORCHVISION_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;vision&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_vision_available</span><span class="p">,</span> <span class="n">VISION_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;scipy&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_scipy_available</span><span class="p">,</span> <span class="n">SCIPY_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;accelerate&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_accelerate_available</span><span class="p">,</span> <span class="n">ACCELERATE_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;oneccl_bind_pt&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_ccl_available</span><span class="p">,</span> <span class="n">CCL_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;cython&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_cython_available</span><span class="p">,</span> <span class="n">CYTHON_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;jieba&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_jieba_available</span><span class="p">,</span> <span class="n">JIEBA_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;peft&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_peft_available</span><span class="p">,</span> <span class="n">PEFT_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;jinja&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_jinja_available</span><span class="p">,</span> <span class="n">JINJA_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;yt_dlp&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_yt_dlp_available</span><span class="p">,</span> <span class="n">YT_DLP_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;rich&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_rich_available</span><span class="p">,</span> <span class="n">RICH_IMPORT_ERROR</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;keras_nlp&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">is_keras_nlp_available</span><span class="p">,</span> <span class="n">KERAS_NLP_IMPORT_ERROR</span><span class="p">)),</span>
    <span class="p">]</span>
<span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">requires_backends</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">backends</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">backends</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="n">backends</span> <span class="o">=</span> <span class="p">[</span><span class="n">backends</span><span class="p">]</span>

    <span class="n">name</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;__name__&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">obj</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>

    <span class="c1"># Raise an error for users who might not realize that classes without &quot;TF&quot; are torch-only</span>
    <span class="k">if</span> <span class="s2">&quot;torch&quot;</span> <span class="ow">in</span> <span class="n">backends</span> <span class="ow">and</span> <span class="s2">&quot;tf&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">backends</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_torch_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">is_tf_available</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="n">PYTORCH_IMPORT_ERROR_WITH_TF</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>

    <span class="c1"># Raise the inverse error for PyTorch users trying to load TF classes</span>
    <span class="k">if</span> <span class="s2">&quot;tf&quot;</span> <span class="ow">in</span> <span class="n">backends</span> <span class="ow">and</span> <span class="s2">&quot;torch&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">backends</span> <span class="ow">and</span> <span class="n">is_torch_available</span><span class="p">()</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_tf_available</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="n">TF_IMPORT_ERROR_WITH_PYTORCH</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>

    <span class="n">failed</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">backend</span> <span class="ow">in</span> <span class="n">backends</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">backend</span><span class="p">,</span> <span class="n">Backend</span><span class="p">):</span>
            <span class="n">available</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">is_satisfied</span><span class="p">,</span> <span class="n">backend</span><span class="o">.</span><span class="n">error_message</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">available</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="n">BACKENDS_MAPPING</span><span class="p">[</span><span class="n">backend</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">available</span><span class="p">():</span>
            <span class="n">failed</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">failed</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">failed</span><span class="p">))</span>


<span class="k">class</span><span class="w"> </span><span class="nc">DummyObject</span><span class="p">(</span><span class="nb">type</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Metaclass for the dummy objects. Any class inheriting from it will return the ImportError generated by</span>
<span class="sd">    `requires_backend` each time a user tries to access any method of that class.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">is_dummy</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getattribute__</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">key</span> <span class="o">!=</span> <span class="s2">&quot;_from_config&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;is_dummy&quot;</span> <span class="ow">or</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;mro&quot;</span> <span class="ow">or</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;call&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__getattribute__</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="n">requires_backends</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_backends</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_torch_fx_proxy</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">is_torch_fx_available</span><span class="p">():</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">torch.fx</span>

        <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">Proxy</span><span class="p">)</span>
    <span class="k">return</span> <span class="kc">False</span>


<span class="n">BACKENDS_T</span> <span class="o">=</span> <span class="n">FrozenSet</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
<span class="n">IMPORT_STRUCTURE_T</span> <span class="o">=</span> <span class="n">Dict</span><span class="p">[</span><span class="n">BACKENDS_T</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_LazyModule</span><span class="p">(</span><span class="n">ModuleType</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Module class that surfaces all objects but only performs associated imports when the objects are requested.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Very heavily inspired by optuna.integration._IntegrationModule</span>
    <span class="c1"># https://github.com/optuna/optuna/blob/master/optuna/integration/__init__.py</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">module_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">import_structure</span><span class="p">:</span> <span class="n">IMPORT_STRUCTURE_T</span><span class="p">,</span>
        <span class="n">module_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">importlib</span><span class="o">.</span><span class="n">machinery</span><span class="o">.</span><span class="n">ModuleSpec</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">extra_objects</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">object</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">explicit_import_shortcut</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_object_missing_backend</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_explicit_import_shortcut</span> <span class="o">=</span> <span class="n">explicit_import_shortcut</span> <span class="k">if</span> <span class="n">explicit_import_shortcut</span> <span class="k">else</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">frozenset</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">import_structure</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_class_to_module</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__all__</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="n">_import_structure</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="k">for</span> <span class="n">backends</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">import_structure</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">missing_backends</span> <span class="o">=</span> <span class="p">[]</span>

                <span class="c1"># This ensures that if a module is importable, then all other keys of the module are importable.</span>
                <span class="c1"># As an example, in module.keys() we might have the following:</span>
                <span class="c1">#</span>
                <span class="c1"># dict_keys([&#39;models.nllb_moe.configuration_nllb_moe&#39;, &#39;models.sew_d.configuration_sew_d&#39;])</span>
                <span class="c1">#</span>
                <span class="c1"># with this, we don&#39;t only want to be able to import these explicitly, we want to be able to import</span>
                <span class="c1"># every intermediate module as well. Therefore, this is what is returned:</span>
                <span class="c1">#</span>
                <span class="c1"># {</span>
                <span class="c1">#     &#39;models.nllb_moe.configuration_nllb_moe&#39;,</span>
                <span class="c1">#     &#39;models.sew_d.configuration_sew_d&#39;,</span>
                <span class="c1">#     &#39;models&#39;,</span>
                <span class="c1">#     &#39;models.sew_d&#39;, &#39;models.nllb_moe&#39;</span>
                <span class="c1"># }</span>

                <span class="n">module_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span>
                    <span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[[</span><span class="n">k</span><span class="o">.</span><span class="n">rsplit</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">keys</span><span class="p">())])</span>
                <span class="p">)</span>

                <span class="k">for</span> <span class="n">backend</span> <span class="ow">in</span> <span class="n">backends</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">backend</span> <span class="ow">in</span> <span class="n">BACKENDS_MAPPING</span><span class="p">:</span>
                        <span class="nb">callable</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">BACKENDS_MAPPING</span><span class="p">[</span><span class="n">backend</span><span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">key</span> <span class="ow">in</span> <span class="n">backend</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;=&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&gt;&quot;</span><span class="p">]):</span>
                            <span class="n">backend</span> <span class="o">=</span> <span class="n">Backend</span><span class="p">(</span><span class="n">backend</span><span class="p">)</span>
                            <span class="nb">callable</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">is_satisfied</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;Backend should be defined in the BACKENDS_MAPPING. Offending backend: </span><span class="si">{</span><span class="n">backend</span><span class="si">}</span><span class="s2">&quot;</span>
                            <span class="p">)</span>

                    <span class="k">try</span><span class="p">:</span>
                        <span class="k">if</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">():</span>
                            <span class="n">missing_backends</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">backend</span><span class="p">)</span>
                    <span class="k">except</span> <span class="p">(</span><span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">PackageNotFoundError</span><span class="p">,</span> <span class="ne">ModuleNotFoundError</span><span class="p">,</span> <span class="ne">RuntimeError</span><span class="p">):</span>
                        <span class="n">missing_backends</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">backend</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">module_keys</span><span class="p">)</span>

                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">values</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">missing_backends</span><span class="p">):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_object_missing_backend</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">missing_backends</span>

                    <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">values</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_class_to_module</span><span class="p">[</span><span class="n">value</span><span class="p">]</span> <span class="o">=</span> <span class="n">key</span>
                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">missing_backends</span><span class="p">):</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_object_missing_backend</span><span class="p">[</span><span class="n">value</span><span class="p">]</span> <span class="o">=</span> <span class="n">missing_backends</span>
                    <span class="n">_import_structure</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="p">[])</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>

                <span class="c1"># Needed for autocompletion in an IDE</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__all__</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">module_keys</span> <span class="o">|</span> <span class="nb">set</span><span class="p">(</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="n">module</span><span class="o">.</span><span class="n">values</span><span class="p">())))</span>

            <span class="bp">self</span><span class="o">.</span><span class="vm">__file__</span> <span class="o">=</span> <span class="n">module_file</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__spec__</span> <span class="o">=</span> <span class="n">module_spec</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__path__</span> <span class="o">=</span> <span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">module_file</span><span class="p">)]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_objects</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">extra_objects</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">extra_objects</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="n">name</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_import_structure</span> <span class="o">=</span> <span class="n">_import_structure</span>

        <span class="c1"># This can be removed once every exportable object has a `require()` require.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">import_structure</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_class_to_module</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">values</span> <span class="ow">in</span> <span class="n">import_structure</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">values</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_class_to_module</span><span class="p">[</span><span class="n">value</span><span class="p">]</span> <span class="o">=</span> <span class="n">key</span>
            <span class="c1"># Needed for autocompletion in an IDE</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__all__</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">import_structure</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="n">import_structure</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__file__</span> <span class="o">=</span> <span class="n">module_file</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__spec__</span> <span class="o">=</span> <span class="n">module_spec</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__path__</span> <span class="o">=</span> <span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">module_file</span><span class="p">)]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_objects</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">extra_objects</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">extra_objects</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="n">name</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_import_structure</span> <span class="o">=</span> <span class="n">import_structure</span>

    <span class="c1"># Needed for autocompletion in an IDE</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__dir__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__dir__</span><span class="p">()</span>
        <span class="c1"># The elements of self.__all__ that are submodules may or may not be in the dir already, depending on whether</span>
        <span class="c1"># they have been accessed or not. So we only add the elements of self.__all__ that are not already in the dir.</span>
        <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">__all__</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">attr</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">result</span><span class="p">:</span>
                <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_objects</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_objects</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_object_missing_backend</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">missing_backends</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_object_missing_backend</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>

            <span class="k">class</span><span class="w"> </span><span class="nc">Placeholder</span><span class="p">(</span><span class="n">metaclass</span><span class="o">=</span><span class="n">DummyObject</span><span class="p">):</span>
                <span class="n">_backends</span> <span class="o">=</span> <span class="n">missing_backends</span>

                <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
                    <span class="n">requires_backends</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">missing_backends</span><span class="p">)</span>

                <span class="k">def</span><span class="w"> </span><span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
                    <span class="k">pass</span>

            <span class="n">Placeholder</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">=</span> <span class="n">name</span>

            <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_class_to_module</span><span class="p">:</span>
                <span class="n">module_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;transformers.</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">module_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_class_to_module</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">module_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;transformers.&quot;</span><span class="p">):</span>
                    <span class="n">module_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;transformers.</span><span class="si">{</span><span class="n">module_name</span><span class="si">}</span><span class="s2">&quot;</span>

            <span class="n">Placeholder</span><span class="o">.</span><span class="vm">__module__</span> <span class="o">=</span> <span class="n">module_name</span>

            <span class="n">value</span> <span class="o">=</span> <span class="n">Placeholder</span>
        <span class="k">elif</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_class_to_module</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_module</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_class_to_module</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
                <span class="n">value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="ne">ModuleNotFoundError</span><span class="p">,</span> <span class="ne">RuntimeError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ModuleNotFoundError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Could not import module &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;. Are this object&#39;s requirements defined correctly?&quot;</span>
                <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>

        <span class="k">elif</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_module</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="ne">ModuleNotFoundError</span><span class="p">,</span> <span class="ne">RuntimeError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ModuleNotFoundError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Could not import module &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;. Are this object&#39;s requirements defined correctly?&quot;</span>
                <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">value</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">values</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_explicit_import_shortcut</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">values</span><span class="p">:</span>
                    <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_module</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;module </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> has no attribute </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">value</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_module</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">importlib</span><span class="o">.</span><span class="n">import_module</span><span class="p">(</span><span class="s2">&quot;.&quot;</span> <span class="o">+</span> <span class="n">module_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">e</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__reduce__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__file__</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_import_structure</span><span class="p">))</span>


<span class="k">class</span><span class="w"> </span><span class="nc">OptionalDependencyNotAvailable</span><span class="p">(</span><span class="ne">BaseException</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Internally used error class for signalling an optional dependency was not found.&quot;&quot;&quot;</span>


<span class="k">def</span><span class="w"> </span><span class="nf">direct_transformers_import</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="s2">&quot;__init__.py&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModuleType</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Imports transformers directly</span>

<span class="sd">    Args:</span>
<span class="sd">        path (`str`): The path to the source file</span>
<span class="sd">        file (`str`, *optional*): The file to join with the path. Defaults to &quot;__init__.py&quot;.</span>

<span class="sd">    Returns:</span>
<span class="sd">        `ModuleType`: The resulting imported module</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;transformers&quot;</span>
    <span class="n">location</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">file</span><span class="p">)</span>
    <span class="n">spec</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">spec_from_file_location</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">location</span><span class="p">,</span> <span class="n">submodule_search_locations</span><span class="o">=</span><span class="p">[</span><span class="n">path</span><span class="p">])</span>
    <span class="n">module</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">module_from_spec</span><span class="p">(</span><span class="n">spec</span><span class="p">)</span>
    <span class="n">spec</span><span class="o">.</span><span class="n">loader</span><span class="o">.</span><span class="n">exec_module</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
    <span class="n">module</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">module</span>


<span class="k">class</span><span class="w"> </span><span class="nc">VersionComparison</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="n">EQUAL</span> <span class="o">=</span> <span class="n">operator</span><span class="o">.</span><span class="n">eq</span>
    <span class="n">NOT_EQUAL</span> <span class="o">=</span> <span class="n">operator</span><span class="o">.</span><span class="n">ne</span>
    <span class="n">GREATER_THAN</span> <span class="o">=</span> <span class="n">operator</span><span class="o">.</span><span class="n">gt</span>
    <span class="n">LESS_THAN</span> <span class="o">=</span> <span class="n">operator</span><span class="o">.</span><span class="n">lt</span>
    <span class="n">GREATER_THAN_OR_EQUAL</span> <span class="o">=</span> <span class="n">operator</span><span class="o">.</span><span class="n">ge</span>
    <span class="n">LESS_THAN_OR_EQUAL</span> <span class="o">=</span> <span class="n">operator</span><span class="o">.</span><span class="n">le</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_string</span><span class="p">(</span><span class="n">version_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;VersionComparison&quot;</span><span class="p">:</span>
        <span class="n">string_to_operator</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;=&quot;</span><span class="p">:</span> <span class="n">VersionComparison</span><span class="o">.</span><span class="n">EQUAL</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
            <span class="s2">&quot;==&quot;</span><span class="p">:</span> <span class="n">VersionComparison</span><span class="o">.</span><span class="n">EQUAL</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
            <span class="s2">&quot;!=&quot;</span><span class="p">:</span> <span class="n">VersionComparison</span><span class="o">.</span><span class="n">NOT_EQUAL</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
            <span class="s2">&quot;&gt;&quot;</span><span class="p">:</span> <span class="n">VersionComparison</span><span class="o">.</span><span class="n">GREATER_THAN</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
            <span class="s2">&quot;&lt;&quot;</span><span class="p">:</span> <span class="n">VersionComparison</span><span class="o">.</span><span class="n">LESS_THAN</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
            <span class="s2">&quot;&gt;=&quot;</span><span class="p">:</span> <span class="n">VersionComparison</span><span class="o">.</span><span class="n">GREATER_THAN_OR_EQUAL</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
            <span class="s2">&quot;&lt;=&quot;</span><span class="p">:</span> <span class="n">VersionComparison</span><span class="o">.</span><span class="n">LESS_THAN_OR_EQUAL</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="n">string_to_operator</span><span class="p">[</span><span class="n">version_string</span><span class="p">]</span>


<span class="nd">@lru_cache</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">split_package_version</span><span class="p">(</span><span class="n">package_version_str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
    <span class="n">pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;([a-zA-Z0-9_-]+)([!&lt;&gt;=~]+)([0-9.]+)&quot;</span>
    <span class="n">match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">package_version_str</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">match</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid package version string: </span><span class="si">{</span><span class="n">package_version_str</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">Backend</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">backend_requirement</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">package_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">version_comparison</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">version</span> <span class="o">=</span> <span class="n">split_package_version</span><span class="p">(</span><span class="n">backend_requirement</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">package_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">BACKENDS_MAPPING</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Backends should be defined in the BACKENDS_MAPPING. Offending backend: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">package_name</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">is_satisfied</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">VersionComparison</span><span class="o">.</span><span class="n">from_string</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">version_comparison</span><span class="p">)(</span>
            <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">package_name</span><span class="p">)),</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">version</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;Backend(&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">package_name</span><span class="si">}</span><span class="s1">&quot;, </span><span class="si">{</span><span class="n">VersionComparison</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">version_comparison</span><span class="p">]</span><span class="si">}</span><span class="s1">, &quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">version</span><span class="si">}</span><span class="s1">&quot;)&#39;</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">error_message</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="se">{{</span><span class="s2">0</span><span class="se">}}</span><span class="s2"> requires the </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">package_name</span><span class="si">}</span><span class="s2"> library version </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">version_comparison</span><span class="si">}{</span><span class="bp">self</span><span class="o">.</span><span class="n">version</span><span class="si">}</span><span class="s2">. That&quot;</span>
            <span class="sa">f</span><span class="s2">&quot; library was not found with this version in your environment.&quot;</span>
        <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">requires</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">backends</span><span class="o">=</span><span class="p">()):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This decorator enables two things:</span>
<span class="sd">    - Attaching a `__backends` tuple to an object to see what are the necessary backends for it</span>
<span class="sd">      to execute correctly without instantiating it</span>
<span class="sd">    - The &#39;@requires&#39; string is used to dynamically import objects</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">backends</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Backends should be a tuple.&quot;</span><span class="p">)</span>

    <span class="n">applied_backends</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">backend</span> <span class="ow">in</span> <span class="n">backends</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">backend</span> <span class="ow">in</span> <span class="n">BACKENDS_MAPPING</span><span class="p">:</span>
            <span class="n">applied_backends</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">backend</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">key</span> <span class="ow">in</span> <span class="n">backend</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;=&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&gt;&quot;</span><span class="p">]):</span>
                <span class="n">applied_backends</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Backend</span><span class="p">(</span><span class="n">backend</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Backend should be defined in the BACKENDS_MAPPING. Offending backend: </span><span class="si">{</span><span class="n">backend</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">inner_fn</span><span class="p">(</span><span class="n">fun</span><span class="p">):</span>
        <span class="n">fun</span><span class="o">.</span><span class="n">__backends</span> <span class="o">=</span> <span class="n">applied_backends</span>
        <span class="k">return</span> <span class="n">fun</span>

    <span class="k">return</span> <span class="n">inner_fn</span>


<span class="n">BASE_FILE_REQUIREMENTS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="k">lambda</span> <span class="n">e</span><span class="p">:</span> <span class="s2">&quot;modeling_tf_&quot;</span> <span class="ow">in</span> <span class="n">e</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;tf&quot;</span><span class="p">,),</span>
    <span class="k">lambda</span> <span class="n">e</span><span class="p">:</span> <span class="s2">&quot;modeling_flax_&quot;</span> <span class="ow">in</span> <span class="n">e</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;flax&quot;</span><span class="p">,),</span>
    <span class="k">lambda</span> <span class="n">e</span><span class="p">:</span> <span class="s2">&quot;modeling_&quot;</span> <span class="ow">in</span> <span class="n">e</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;torch&quot;</span><span class="p">,),</span>
    <span class="k">lambda</span> <span class="n">e</span><span class="p">:</span> <span class="n">e</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;tokenization_&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">e</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;_fast&quot;</span><span class="p">):</span> <span class="p">(</span><span class="s2">&quot;tokenizers&quot;</span><span class="p">,),</span>
    <span class="k">lambda</span> <span class="n">e</span><span class="p">:</span> <span class="n">e</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;image_processing_&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">e</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;_fast&quot;</span><span class="p">):</span> <span class="p">(</span><span class="s2">&quot;vision&quot;</span><span class="p">,</span> <span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="s2">&quot;torchvision&quot;</span><span class="p">),</span>
    <span class="k">lambda</span> <span class="n">e</span><span class="p">:</span> <span class="n">e</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;image_processing_&quot;</span><span class="p">):</span> <span class="p">(</span><span class="s2">&quot;vision&quot;</span><span class="p">,),</span>
<span class="p">}</span>


<span class="k">def</span><span class="w"> </span><span class="nf">fetch__all__</span><span class="p">(</span><span class="n">file_content</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the content of the __all__ variable in the file content.</span>
<span class="sd">    Returns None if not defined, otherwise returns a list of strings.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="s2">&quot;__all__&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">file_content</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[]</span>

    <span class="n">start_index</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="n">file_content</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lines</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">line</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;__all__&quot;</span><span class="p">):</span>
            <span class="n">start_index</span> <span class="o">=</span> <span class="n">index</span>

    <span class="c1"># There is no line starting with `__all__`</span>
    <span class="k">if</span> <span class="n">start_index</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[]</span>

    <span class="n">lines</span> <span class="o">=</span> <span class="n">lines</span><span class="p">[</span><span class="n">start_index</span><span class="p">:]</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">lines</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;__all__&quot;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;fetch__all__ accepts a list of lines, with the first line being the __all__ variable declaration&quot;</span>
        <span class="p">)</span>

    <span class="c1"># __all__ is defined on a single line</span>
    <span class="k">if</span> <span class="n">lines</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;]&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">obj</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\&quot;</span><span class="s2">&#39; &quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s2">&quot; []&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">)]</span>

    <span class="c1"># __all__ is defined on multiple lines</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">_all</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">__all__line_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">lines</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">lines</span><span class="p">[</span><span class="n">__all__line_index</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;]&quot;</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">_all</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">_all</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lines</span><span class="p">[</span><span class="n">__all__line_index</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\&quot;</span><span class="s2">&#39;, &quot;</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">_all</span>


<span class="nd">@lru_cache</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">create_import_structure_from_path</span><span class="p">(</span><span class="n">module_path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This method takes the path to a file/a folder and returns the import structure.</span>
<span class="sd">    If a file is given, it will return the import structure of the parent folder.</span>

<span class="sd">    Import structures are designed to be digestible by `_LazyModule` objects. They are</span>
<span class="sd">    created from the __all__ definitions in each files as well as the `@require` decorators</span>
<span class="sd">    above methods and objects.</span>

<span class="sd">    The import structure allows explicit display of the required backends for a given object.</span>
<span class="sd">    These backends are specified in two ways:</span>

<span class="sd">    1. Through their `@require`, if they are exported with that decorator. This `@require` decorator</span>
<span class="sd">       accepts a `backend` tuple kwarg mentioning which backends are required to run this object.</span>

<span class="sd">    2. If an object is defined in a file with &quot;default&quot; backends, it will have, at a minimum, this</span>
<span class="sd">       backend specified. The default backends are defined according to the filename:</span>

<span class="sd">       - If a file is named like `modeling_*.py`, it will have a `torch` backend</span>
<span class="sd">       - If a file is named like `modeling_tf_*.py`, it will have a `tf` backend</span>
<span class="sd">       - If a file is named like `modeling_flax_*.py`, it will have a `flax` backend</span>
<span class="sd">       - If a file is named like `tokenization_*_fast.py`, it will have a `tokenizers` backend</span>
<span class="sd">       - If a file is named like `image_processing*_fast.py`, it will have a `torchvision` + `torch` backend</span>

<span class="sd">    Backends serve the purpose of displaying a clear error message to the user in case the backends are not installed.</span>
<span class="sd">    Should an object be imported without its required backends being in the environment, any attempt to use the</span>
<span class="sd">    object will raise an error mentioning which backend(s) should be added to the environment in order to use</span>
<span class="sd">    that object.</span>

<span class="sd">    Here&#39;s an example of an input import structure at the src.transformers.models level:</span>

<span class="sd">    {</span>
<span class="sd">        &#39;albert&#39;: {</span>
<span class="sd">            frozenset(): {</span>
<span class="sd">                &#39;configuration_albert&#39;: {&#39;AlbertConfig&#39;, &#39;AlbertOnnxConfig&#39;}</span>
<span class="sd">            },</span>
<span class="sd">            frozenset({&#39;tokenizers&#39;}): {</span>
<span class="sd">                &#39;tokenization_albert_fast&#39;: {&#39;AlbertTokenizerFast&#39;}</span>
<span class="sd">            },</span>
<span class="sd">        },</span>
<span class="sd">        &#39;align&#39;: {</span>
<span class="sd">            frozenset(): {</span>
<span class="sd">                &#39;configuration_align&#39;: {&#39;AlignConfig&#39;, &#39;AlignTextConfig&#39;, &#39;AlignVisionConfig&#39;},</span>
<span class="sd">                &#39;processing_align&#39;: {&#39;AlignProcessor&#39;}</span>
<span class="sd">            },</span>
<span class="sd">        },</span>
<span class="sd">        &#39;altclip&#39;: {</span>
<span class="sd">            frozenset(): {</span>
<span class="sd">                &#39;configuration_altclip&#39;: {&#39;AltCLIPConfig&#39;, &#39;AltCLIPTextConfig&#39;, &#39;AltCLIPVisionConfig&#39;},</span>
<span class="sd">                &#39;processing_altclip&#39;: {&#39;AltCLIPProcessor&#39;},</span>
<span class="sd">            }</span>
<span class="sd">        }</span>
<span class="sd">    }</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">import_structure</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">module_path</span><span class="p">):</span>
        <span class="n">module_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">module_path</span><span class="p">)</span>

    <span class="n">directory</span> <span class="o">=</span> <span class="n">module_path</span>
    <span class="n">adjacent_modules</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">module_path</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">f</span> <span class="o">!=</span> <span class="s2">&quot;__pycache__&quot;</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">module_path</span><span class="p">,</span> <span class="n">f</span><span class="p">)):</span>
            <span class="n">import_structure</span><span class="p">[</span><span class="n">f</span><span class="p">]</span> <span class="o">=</span> <span class="n">create_import_structure_from_path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">module_path</span><span class="p">,</span> <span class="n">f</span><span class="p">))</span>

        <span class="k">elif</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="n">f</span><span class="p">)):</span>
            <span class="n">adjacent_modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="c1"># We&#39;re only taking a look at files different from __init__.py</span>
    <span class="c1"># We could theoretically require things directly from the __init__.py</span>
    <span class="c1"># files, but this is not supported at this time.</span>
    <span class="k">if</span> <span class="s2">&quot;__init__.py&quot;</span> <span class="ow">in</span> <span class="n">adjacent_modules</span><span class="p">:</span>
        <span class="n">adjacent_modules</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;__init__.py&quot;</span><span class="p">)</span>

    <span class="c1"># Modular files should not be imported</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">find_substring</span><span class="p">(</span><span class="n">substring</span><span class="p">,</span> <span class="n">list_</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">any</span><span class="p">(</span><span class="n">substring</span> <span class="ow">in</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">list_</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">find_substring</span><span class="p">(</span><span class="s2">&quot;modular_&quot;</span><span class="p">,</span> <span class="n">adjacent_modules</span><span class="p">)</span> <span class="ow">and</span> <span class="n">find_substring</span><span class="p">(</span><span class="s2">&quot;modeling_&quot;</span><span class="p">,</span> <span class="n">adjacent_modules</span><span class="p">):</span>
        <span class="n">adjacent_modules</span> <span class="o">=</span> <span class="p">[</span><span class="n">module</span> <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">adjacent_modules</span> <span class="k">if</span> <span class="s2">&quot;modular_&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">module</span><span class="p">]</span>

    <span class="n">module_requirements</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">module_name</span> <span class="ow">in</span> <span class="n">adjacent_modules</span><span class="p">:</span>
        <span class="c1"># Only modules ending in `.py` are accepted here.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">module_name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.py&quot;</span><span class="p">):</span>
            <span class="k">continue</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="n">module_name</span><span class="p">),</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">file_content</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

        <span class="c1"># Remove the .py suffix</span>
        <span class="n">module_name</span> <span class="o">=</span> <span class="n">module_name</span><span class="p">[:</span><span class="o">-</span><span class="mi">3</span><span class="p">]</span>

        <span class="n">previous_line</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="n">previous_index</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Some files have some requirements by default.</span>
        <span class="c1"># For example, any file named `modeling_tf_xxx.py`</span>
        <span class="c1"># should have TensorFlow as a required backend.</span>
        <span class="n">base_requirements</span> <span class="o">=</span> <span class="p">()</span>
        <span class="k">for</span> <span class="n">string_check</span><span class="p">,</span> <span class="n">requirements</span> <span class="ow">in</span> <span class="n">BASE_FILE_REQUIREMENTS</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">string_check</span><span class="p">(</span><span class="n">module_name</span><span class="p">):</span>
                <span class="n">base_requirements</span> <span class="o">=</span> <span class="n">requirements</span>
                <span class="k">break</span>

        <span class="c1"># Objects that have a `@require` assigned to them will get exported</span>
        <span class="c1"># with the backends specified in the decorator as well as the file backends.</span>
        <span class="n">exported_objects</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">if</span> <span class="s2">&quot;@requires&quot;</span> <span class="ow">in</span> <span class="n">file_content</span><span class="p">:</span>
            <span class="n">lines</span> <span class="o">=</span> <span class="n">file_content</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lines</span><span class="p">):</span>
                <span class="c1"># This allows exporting items with other decorators. We&#39;ll take a look</span>
                <span class="c1"># at the line that follows at the same indentation level.</span>
                <span class="k">if</span> <span class="n">line</span><span class="o">.</span><span class="n">startswith</span><span class="p">((</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;@&quot;</span><span class="p">,</span> <span class="s2">&quot;)&quot;</span><span class="p">))</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">line</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;@requires&quot;</span><span class="p">):</span>
                    <span class="k">continue</span>

                <span class="c1"># Skipping line enables putting whatever we want between the</span>
                <span class="c1"># export() call and the actual class/method definition.</span>
                <span class="c1"># This is what enables having # Copied from statements, docs, etc.</span>
                <span class="n">skip_line</span> <span class="o">=</span> <span class="kc">False</span>

                <span class="k">if</span> <span class="s2">&quot;@requires&quot;</span> <span class="ow">in</span> <span class="n">previous_line</span><span class="p">:</span>
                    <span class="n">skip_line</span> <span class="o">=</span> <span class="kc">False</span>

                    <span class="c1"># Backends are defined on the same line as export</span>
                    <span class="k">if</span> <span class="s2">&quot;backends&quot;</span> <span class="ow">in</span> <span class="n">previous_line</span><span class="p">:</span>
                        <span class="n">backends_string</span> <span class="o">=</span> <span class="n">previous_line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;backends=&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;(&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;)&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="n">backends</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">sorted</span><span class="p">([</span><span class="n">b</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s2">&quot;&#39;</span><span class="se">\&quot;</span><span class="s2">,&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">backends_string</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">b</span><span class="p">]))</span>

                    <span class="c1"># Backends are defined in the lines following export, for example such as:</span>
                    <span class="c1"># @export(</span>
                    <span class="c1">#     backends=(</span>
                    <span class="c1">#             &quot;sentencepiece&quot;,</span>
                    <span class="c1">#             &quot;torch&quot;,</span>
                    <span class="c1">#             &quot;tf&quot;,</span>
                    <span class="c1">#     )</span>
                    <span class="c1"># )</span>
                    <span class="c1">#</span>
                    <span class="c1"># or</span>
                    <span class="c1">#</span>
                    <span class="c1"># @export(</span>
                    <span class="c1">#     backends=(</span>
                    <span class="c1">#             &quot;sentencepiece&quot;, &quot;tf&quot;</span>
                    <span class="c1">#     )</span>
                    <span class="c1"># )</span>
                    <span class="k">elif</span> <span class="s2">&quot;backends&quot;</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">[</span><span class="n">previous_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]:</span>
                        <span class="n">backends</span> <span class="o">=</span> <span class="p">[]</span>
                        <span class="k">for</span> <span class="n">backend_line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">[</span><span class="n">previous_index</span><span class="p">:</span><span class="n">index</span><span class="p">]:</span>
                            <span class="k">if</span> <span class="s2">&quot;backends&quot;</span> <span class="ow">in</span> <span class="n">backend_line</span><span class="p">:</span>
                                <span class="n">backend_line</span> <span class="o">=</span> <span class="n">backend_line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
                            <span class="k">if</span> <span class="s1">&#39;&quot;&#39;</span> <span class="ow">in</span> <span class="n">backend_line</span> <span class="ow">or</span> <span class="s2">&quot;&#39;&quot;</span> <span class="ow">in</span> <span class="n">backend_line</span><span class="p">:</span>
                                <span class="k">if</span> <span class="s2">&quot;, &quot;</span> <span class="ow">in</span> <span class="n">backend_line</span><span class="p">:</span>
                                    <span class="n">backends</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">backend</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s2">&quot;()</span><span class="se">\&quot;</span><span class="s2">&#39;, &quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">backend</span> <span class="ow">in</span> <span class="n">backend_line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="p">))</span>
                                <span class="k">else</span><span class="p">:</span>
                                    <span class="n">backends</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">backend_line</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s2">&quot;()</span><span class="se">\&quot;</span><span class="s2">&#39;, &quot;</span><span class="p">))</span>

                            <span class="c1"># If the line is only a &#39;)&#39;, then we reached the end of the backends and we break.</span>
                            <span class="k">if</span> <span class="n">backend_line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;)&quot;</span><span class="p">:</span>
                                <span class="k">break</span>
                        <span class="n">backends</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">backends</span><span class="p">)</span>

                    <span class="c1"># No backends are registered for export</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">backends</span> <span class="o">=</span> <span class="p">()</span>

                    <span class="n">backends</span> <span class="o">=</span> <span class="nb">frozenset</span><span class="p">(</span><span class="n">backends</span> <span class="o">+</span> <span class="n">base_requirements</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">backends</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">module_requirements</span><span class="p">:</span>
                        <span class="n">module_requirements</span><span class="p">[</span><span class="n">backends</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
                    <span class="k">if</span> <span class="n">module_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">module_requirements</span><span class="p">[</span><span class="n">backends</span><span class="p">]:</span>
                        <span class="n">module_requirements</span><span class="p">[</span><span class="n">backends</span><span class="p">][</span><span class="n">module_name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

                    <span class="k">if</span> <span class="ow">not</span> <span class="n">line</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;class&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">line</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;def&quot;</span><span class="p">):</span>
                        <span class="n">skip_line</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">start_index</span> <span class="o">=</span> <span class="mi">6</span> <span class="k">if</span> <span class="n">line</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;class&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">4</span>
                        <span class="n">object_name</span> <span class="o">=</span> <span class="n">line</span><span class="p">[</span><span class="n">start_index</span><span class="p">:]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;(&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s2">&quot;:&quot;</span><span class="p">)</span>
                        <span class="n">module_requirements</span><span class="p">[</span><span class="n">backends</span><span class="p">][</span><span class="n">module_name</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">object_name</span><span class="p">)</span>
                        <span class="n">exported_objects</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">object_name</span><span class="p">)</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="n">skip_line</span><span class="p">:</span>
                    <span class="n">previous_line</span> <span class="o">=</span> <span class="n">line</span>
                    <span class="n">previous_index</span> <span class="o">=</span> <span class="n">index</span>

        <span class="c1"># All objects that are in __all__ should be exported by default.</span>
        <span class="c1"># These objects are exported with the file backends.</span>
        <span class="k">if</span> <span class="s2">&quot;__all__&quot;</span> <span class="ow">in</span> <span class="n">file_content</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">_all_object</span> <span class="ow">in</span> <span class="n">fetch__all__</span><span class="p">(</span><span class="n">file_content</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">_all_object</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">exported_objects</span><span class="p">:</span>
                    <span class="n">backends</span> <span class="o">=</span> <span class="nb">frozenset</span><span class="p">(</span><span class="n">base_requirements</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">backends</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">module_requirements</span><span class="p">:</span>
                        <span class="n">module_requirements</span><span class="p">[</span><span class="n">backends</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
                    <span class="k">if</span> <span class="n">module_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">module_requirements</span><span class="p">[</span><span class="n">backends</span><span class="p">]:</span>
                        <span class="n">module_requirements</span><span class="p">[</span><span class="n">backends</span><span class="p">][</span><span class="n">module_name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

                    <span class="n">module_requirements</span><span class="p">[</span><span class="n">backends</span><span class="p">][</span><span class="n">module_name</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">_all_object</span><span class="p">)</span>

    <span class="n">import_structure</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">module_requirements</span><span class="p">,</span> <span class="o">**</span><span class="n">import_structure</span><span class="p">}</span>
    <span class="k">return</span> <span class="n">import_structure</span>


<span class="k">def</span><span class="w"> </span><span class="nf">spread_import_structure</span><span class="p">(</span><span class="n">nested_import_structure</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This method takes as input an unordered import structure and brings the required backends at the top-level,</span>
<span class="sd">    aggregating modules and objects under their required backends.</span>

<span class="sd">    Here&#39;s an example of an input import structure at the src.transformers.models level:</span>

<span class="sd">    {</span>
<span class="sd">        &#39;albert&#39;: {</span>
<span class="sd">            frozenset(): {</span>
<span class="sd">                &#39;configuration_albert&#39;: {&#39;AlbertConfig&#39;, &#39;AlbertOnnxConfig&#39;}</span>
<span class="sd">            },</span>
<span class="sd">            frozenset({&#39;tokenizers&#39;}): {</span>
<span class="sd">                &#39;tokenization_albert_fast&#39;: {&#39;AlbertTokenizerFast&#39;}</span>
<span class="sd">            },</span>
<span class="sd">        },</span>
<span class="sd">        &#39;align&#39;: {</span>
<span class="sd">            frozenset(): {</span>
<span class="sd">                &#39;configuration_align&#39;: {&#39;AlignConfig&#39;, &#39;AlignTextConfig&#39;, &#39;AlignVisionConfig&#39;},</span>
<span class="sd">                &#39;processing_align&#39;: {&#39;AlignProcessor&#39;}</span>
<span class="sd">            },</span>
<span class="sd">        },</span>
<span class="sd">        &#39;altclip&#39;: {</span>
<span class="sd">            frozenset(): {</span>
<span class="sd">                &#39;configuration_altclip&#39;: {&#39;AltCLIPConfig&#39;, &#39;AltCLIPTextConfig&#39;, &#39;AltCLIPVisionConfig&#39;},</span>
<span class="sd">                &#39;processing_altclip&#39;: {&#39;AltCLIPProcessor&#39;},</span>
<span class="sd">            }</span>
<span class="sd">        }</span>
<span class="sd">    }</span>

<span class="sd">    Here&#39;s an example of an output import structure at the src.transformers.models level:</span>

<span class="sd">    {</span>
<span class="sd">        frozenset({&#39;tokenizers&#39;}): {</span>
<span class="sd">            &#39;albert.tokenization_albert_fast&#39;: {&#39;AlbertTokenizerFast&#39;}</span>
<span class="sd">        },</span>
<span class="sd">        frozenset(): {</span>
<span class="sd">            &#39;albert.configuration_albert&#39;: {&#39;AlbertConfig&#39;, &#39;AlbertOnnxConfig&#39;},</span>
<span class="sd">            &#39;align.processing_align&#39;: {&#39;AlignProcessor&#39;},</span>
<span class="sd">            &#39;align.configuration_align&#39;: {&#39;AlignConfig&#39;, &#39;AlignTextConfig&#39;, &#39;AlignVisionConfig&#39;},</span>
<span class="sd">            &#39;altclip.configuration_altclip&#39;: {&#39;AltCLIPConfig&#39;, &#39;AltCLIPTextConfig&#39;, &#39;AltCLIPVisionConfig&#39;},</span>
<span class="sd">            &#39;altclip.processing_altclip&#39;: {&#39;AltCLIPProcessor&#39;}</span>
<span class="sd">        }</span>
<span class="sd">    }</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">propagate_frozenset</span><span class="p">(</span><span class="n">unordered_import_structure</span><span class="p">):</span>
        <span class="n">frozenset_first_import_structure</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">_key</span><span class="p">,</span> <span class="n">_value</span> <span class="ow">in</span> <span class="n">unordered_import_structure</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># If the value is not a dict but a string, no need for custom manipulation</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">_value</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">frozenset_first_import_structure</span><span class="p">[</span><span class="n">_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">_value</span>

            <span class="k">elif</span> <span class="nb">any</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">frozenset</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">_value</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">_value</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="nb">frozenset</span><span class="p">):</span>
                        <span class="c1"># Here we want to switch around _key and k to propagate k upstream if it is a frozenset</span>
                        <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">frozenset_first_import_structure</span><span class="p">:</span>
                            <span class="n">frozenset_first_import_structure</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
                        <span class="k">if</span> <span class="n">_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">frozenset_first_import_structure</span><span class="p">[</span><span class="n">k</span><span class="p">]:</span>
                            <span class="n">frozenset_first_import_structure</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">_key</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

                        <span class="n">frozenset_first_import_structure</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">_key</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># If k is not a frozenset, it means that the dictionary is not &quot;level&quot;: some keys (top-level)</span>
                        <span class="c1"># are frozensets, whereas some are not -&gt; frozenset keys are at an unkown depth-level of the</span>
                        <span class="c1"># dictionary.</span>
                        <span class="c1">#</span>
                        <span class="c1"># We recursively propagate the frozenset for this specific dictionary so that the frozensets</span>
                        <span class="c1"># are at the top-level when we handle them.</span>
                        <span class="n">propagated_frozenset</span> <span class="o">=</span> <span class="n">propagate_frozenset</span><span class="p">({</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">})</span>
                        <span class="k">for</span> <span class="n">r_k</span><span class="p">,</span> <span class="n">r_v</span> <span class="ow">in</span> <span class="n">propagated_frozenset</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">_key</span><span class="p">,</span> <span class="nb">frozenset</span><span class="p">):</span>
                                <span class="k">if</span> <span class="n">r_k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">frozenset_first_import_structure</span><span class="p">:</span>
                                    <span class="n">frozenset_first_import_structure</span><span class="p">[</span><span class="n">r_k</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
                                <span class="k">if</span> <span class="n">_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">frozenset_first_import_structure</span><span class="p">[</span><span class="n">r_k</span><span class="p">]:</span>
                                    <span class="n">frozenset_first_import_structure</span><span class="p">[</span><span class="n">r_k</span><span class="p">][</span><span class="n">_key</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

                                <span class="c1"># _key is a frozenset -&gt; we switch around the r_k and _key</span>
                                <span class="n">frozenset_first_import_structure</span><span class="p">[</span><span class="n">r_k</span><span class="p">][</span><span class="n">_key</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">r_v</span><span class="p">)</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="k">if</span> <span class="n">_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">frozenset_first_import_structure</span><span class="p">:</span>
                                    <span class="n">frozenset_first_import_structure</span><span class="p">[</span><span class="n">_key</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
                                <span class="k">if</span> <span class="n">r_k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">frozenset_first_import_structure</span><span class="p">[</span><span class="n">_key</span><span class="p">]:</span>
                                    <span class="n">frozenset_first_import_structure</span><span class="p">[</span><span class="n">_key</span><span class="p">][</span><span class="n">r_k</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

                                <span class="c1"># _key is not a frozenset -&gt; we keep the order of r_k and _key</span>
                                <span class="n">frozenset_first_import_structure</span><span class="p">[</span><span class="n">_key</span><span class="p">][</span><span class="n">r_k</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">r_v</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">frozenset_first_import_structure</span><span class="p">[</span><span class="n">_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">propagate_frozenset</span><span class="p">(</span><span class="n">_value</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">frozenset_first_import_structure</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">flatten_dict</span><span class="p">(</span><span class="n">_dict</span><span class="p">,</span> <span class="n">previous_key</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">items</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_key</span><span class="p">,</span> <span class="n">_value</span> <span class="ow">in</span> <span class="n">_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">previous_key</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">_key</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="n">previous_key</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">_key</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">_value</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">items</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">flatten_dict</span><span class="p">(</span><span class="n">_value</span><span class="p">,</span> <span class="n">_key</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">items</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">_key</span><span class="p">,</span> <span class="n">_value</span><span class="p">))</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">items</span><span class="p">)</span>

    <span class="c1"># The tuples contain the necessary backends. We want these first, so we propagate them up the</span>
    <span class="c1"># import structure.</span>
    <span class="n">ordered_import_structure</span> <span class="o">=</span> <span class="n">nested_import_structure</span>

    <span class="c1"># 6 is a number that gives us sufficient depth to go through all files and foreseeable folder depths</span>
    <span class="c1"># while not taking too long to parse.</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
        <span class="n">ordered_import_structure</span> <span class="o">=</span> <span class="n">propagate_frozenset</span><span class="p">(</span><span class="n">ordered_import_structure</span><span class="p">)</span>

    <span class="c1"># We then flatten the dict so that it references a module path.</span>
    <span class="n">flattened_import_structure</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">ordered_import_structure</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">del</span> <span class="n">ordered_import_structure</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">flattened_import_structure</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">flatten_dict</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">flattened_import_structure</span>


<span class="nd">@lru_cache</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">define_import_structure</span><span class="p">(</span><span class="n">module_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">prefix</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">IMPORT_STRUCTURE_T</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This method takes a module_path as input and creates an import structure digestible by a _LazyModule.</span>

<span class="sd">    Here&#39;s an example of an output import structure at the src.transformers.models level:</span>

<span class="sd">    {</span>
<span class="sd">        frozenset({&#39;tokenizers&#39;}): {</span>
<span class="sd">            &#39;albert.tokenization_albert_fast&#39;: {&#39;AlbertTokenizerFast&#39;}</span>
<span class="sd">        },</span>
<span class="sd">        frozenset(): {</span>
<span class="sd">            &#39;albert.configuration_albert&#39;: {&#39;AlbertConfig&#39;, &#39;AlbertOnnxConfig&#39;},</span>
<span class="sd">            &#39;align.processing_align&#39;: {&#39;AlignProcessor&#39;},</span>
<span class="sd">            &#39;align.configuration_align&#39;: {&#39;AlignConfig&#39;, &#39;AlignTextConfig&#39;, &#39;AlignVisionConfig&#39;},</span>
<span class="sd">            &#39;altclip.configuration_altclip&#39;: {&#39;AltCLIPConfig&#39;, &#39;AltCLIPTextConfig&#39;, &#39;AltCLIPVisionConfig&#39;},</span>
<span class="sd">            &#39;altclip.processing_altclip&#39;: {&#39;AltCLIPProcessor&#39;}</span>
<span class="sd">        }</span>
<span class="sd">    }</span>

<span class="sd">    The import structure is a dict defined with frozensets as keys, and dicts of strings to sets of objects.</span>

<span class="sd">    If `prefix` is not None, it will add that prefix to all keys in the returned dict.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">import_structure</span> <span class="o">=</span> <span class="n">create_import_structure_from_path</span><span class="p">(</span><span class="n">module_path</span><span class="p">)</span>
    <span class="n">spread_dict</span> <span class="o">=</span> <span class="n">spread_import_structure</span><span class="p">(</span><span class="n">import_structure</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">prefix</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">spread_dict</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">spread_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="p">{</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">kk</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">vv</span> <span class="k">for</span> <span class="n">kk</span><span class="p">,</span> <span class="n">vv</span> <span class="ow">in</span> <span class="n">v</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">spread_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="k">return</span> <span class="n">spread_dict</span>


<span class="k">def</span><span class="w"> </span><span class="nf">clear_import_cache</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Clear cached Transformers modules to allow reloading modified code.</span>

<span class="sd">    This is useful when actively developing/modifying Transformers code.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Get all transformers modules</span>
    <span class="n">transformers_modules</span> <span class="o">=</span> <span class="p">[</span><span class="n">mod_name</span> <span class="k">for</span> <span class="n">mod_name</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span> <span class="k">if</span> <span class="n">mod_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;transformers.&quot;</span><span class="p">)]</span>

    <span class="c1"># Remove them from sys.modules</span>
    <span class="k">for</span> <span class="n">mod_name</span> <span class="ow">in</span> <span class="n">transformers_modules</span><span class="p">:</span>
        <span class="n">module</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="n">mod_name</span><span class="p">]</span>
        <span class="c1"># Clear _LazyModule caches if applicable</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">_LazyModule</span><span class="p">):</span>
            <span class="n">module</span><span class="o">.</span><span class="n">_objects</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Clear cached objects</span>
        <span class="k">del</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="n">mod_name</span><span class="p">]</span>

    <span class="c1"># Force reload main transformers module</span>
    <span class="k">if</span> <span class="s2">&quot;transformers&quot;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
        <span class="n">main_module</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="s2">&quot;transformers&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">main_module</span><span class="p">,</span> <span class="n">_LazyModule</span><span class="p">):</span>
            <span class="n">main_module</span><span class="o">.</span><span class="n">_objects</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Clear cached objects</span>
        <span class="n">importlib</span><span class="o">.</span><span class="n">reload</span><span class="p">(</span><span class="n">main_module</span><span class="p">)</span>
</pre></div>
        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/scripts/furo.js?v=46bd48cc"></script>
    </body>
</html>